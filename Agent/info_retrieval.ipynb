{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4aaa9e3e",
   "metadata": {},
   "source": [
    "### Do preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ea74578",
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocess\n",
    "\n",
    "train_df, dev_df, dev_baseline_df, test_df, evidence_df = preprocess.return_df()\n",
    "original_train_df, original_dev_df, original_dev_baseline_df, original_test_df, original_evidence_df = preprocess.return_original_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f721f8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   claim_text  \\\n",
      "claim-1937  [scientific, evidence, co2, pollutant, higher,...   \n",
      "claim-126   [el, nio, drove, record, high, global, tempera...   \n",
      "claim-2510                 [1946, pdo, switched, cool, phase]   \n",
      "claim-2021  [weather, channel, cofounder, john, coleman, p...   \n",
      "claim-2449  [january, 2008, capped, 12, month, period, glo...   \n",
      "\n",
      "                claim_label  \\\n",
      "claim-1937         DISPUTED   \n",
      "claim-126           REFUTES   \n",
      "claim-2510         SUPPORTS   \n",
      "claim-2021         DISPUTED   \n",
      "claim-2449  NOT_ENOUGH_INFO   \n",
      "\n",
      "                                                    evidences  \\\n",
      "claim-1937  [evidence-442946, evidence-1194317, evidence-1...   \n",
      "claim-126                 [evidence-338219, evidence-1127398]   \n",
      "claim-2510                 [evidence-530063, evidence-984887]   \n",
      "claim-2021  [evidence-1177431, evidence-782448, evidence-5...   \n",
      "claim-2449  [evidence-1010750, evidence-91661, evidence-72...   \n",
      "\n",
      "                                                 claim_vector  \\\n",
      "claim-1937  [0.010148224420845509, -8.612275269115344e-05,...   \n",
      "claim-126   [-0.01701875776052475, 0.015024662017822266, -...   \n",
      "claim-2510  [0.0042909858748316765, 0.0034185140393674374,...   \n",
      "claim-2021  [-0.00907153356820345, -0.008422908373177052, ...   \n",
      "claim-2449  [-0.010988295078277588, -0.0019697293173521757...   \n",
      "\n",
      "                                             top_100_evidence  \n",
      "claim-1937  [evidence-143269, evidence-796217, evidence-35...  \n",
      "claim-126   [evidence-743888, evidence-372910, evidence-85...  \n",
      "claim-2510  [evidence-130713, evidence-779638, evidence-10...  \n",
      "claim-2021  [evidence-104597, evidence-563911, evidence-37...  \n",
      "claim-2449  [evidence-1205158, evidence-1203993, evidence-...  \n",
      "                                                   claim_text  \\\n",
      "claim-752   [south, australia, expensive, electricity, world]   \n",
      "claim-375   [3, per, cent, total, annual, global, emission...   \n",
      "claim-1266     [mean, world, 1c, warmer, preindustrial, time]   \n",
      "claim-871   [happens, zika, may, also, good, model, second...   \n",
      "claim-2164       [greenland, lost, tiny, fraction, ice, mass]   \n",
      "\n",
      "                claim_label  \\\n",
      "claim-752          SUPPORTS   \n",
      "claim-375   NOT_ENOUGH_INFO   \n",
      "claim-1266         SUPPORTS   \n",
      "claim-871   NOT_ENOUGH_INFO   \n",
      "claim-2164          REFUTES   \n",
      "\n",
      "                                                    evidences  \\\n",
      "claim-752                   [evidence-67732, evidence-572512]   \n",
      "claim-375   [evidence-996421, evidence-1080858, evidence-2...   \n",
      "claim-1266                 [evidence-889933, evidence-694262]   \n",
      "claim-871   [evidence-422399, evidence-702226, evidence-28...   \n",
      "claim-2164  [evidence-52981, evidence-264761, evidence-947...   \n",
      "\n",
      "                                                 claim_vector  \n",
      "claim-752   [-0.00532120605930686, 0.007548254914581776, -...  \n",
      "claim-375   [0.009550761431455612, 0.04579147696495056, 0....  \n",
      "claim-1266  [-0.015976253896951675, -0.015533301047980785,...  \n",
      "claim-871   [0.0040788291953504086, 0.001295375870540738, ...  \n",
      "claim-2164  [0.007402447052299976, -0.0002268463431391865,...  \n",
      "                                                   claim_text  \\\n",
      "claim-752   [south, australia, expensive, electricity, world]   \n",
      "claim-375   [3, per, cent, total, annual, global, emission...   \n",
      "claim-1266     [mean, world, 1c, warmer, preindustrial, time]   \n",
      "claim-871   [happens, zika, may, also, good, model, second...   \n",
      "claim-2164       [greenland, lost, tiny, fraction, ice, mass]   \n",
      "\n",
      "                claim_label  \\\n",
      "claim-752   NOT_ENOUGH_INFO   \n",
      "claim-375   NOT_ENOUGH_INFO   \n",
      "claim-1266         SUPPORTS   \n",
      "claim-871           REFUTES   \n",
      "claim-2164         DISPUTED   \n",
      "\n",
      "                                                    evidences  \\\n",
      "claim-752   [evidence-67732, evidence-572512, evidence-909...   \n",
      "claim-375   [evidence-832334, evidence-699212, evidence-10...   \n",
      "claim-1266  [evidence-315434, evidence-198055, evidence-69...   \n",
      "claim-871   [evidence-303245, evidence-88449, evidence-385...   \n",
      "claim-2164  [evidence-947243, evidence-424102, evidence-91...   \n",
      "\n",
      "                                                 claim_vector  \n",
      "claim-752   [-0.00532120605930686, 0.007548254914581776, -...  \n",
      "claim-375   [0.03033534437417984, 0.04409816861152649, 0.1...  \n",
      "claim-1266  [-0.015976253896951675, -0.015533301047980785,...  \n",
      "claim-871   [0.0040788291953504086, 0.001295375870540738, ...  \n",
      "claim-2164  [0.007402447052299976, -0.0002268463431391865,...  \n",
      "                                                   claim_text\n",
      "claim-2967  [contribution, waste, heat, global, climate, 0...\n",
      "claim-979   [warm, weather, worsened, recent, fiveyear, dr...\n",
      "claim-1609       [greenland, lost, tiny, fraction, ice, mass]\n",
      "claim-1020  [global, reef, crisis, necessarily, mean, exti...\n",
      "claim-2599  [small, amount, active, substance, cause, larg...\n",
      "          key                                              value  \\\n",
      "0  evidence-0  [john, bennet, lawes, english, entrepreneur, a...   \n",
      "1  evidence-1  [lindberg, began, professional, career, age, 1...   \n",
      "2  evidence-2        [boston, lady, cambridge, vampire, weekend]   \n",
      "3  evidence-3  [gerald, francis, goyer, born, october, 20, 19...   \n",
      "4  evidence-4  [detected, abnormality, oxytocinergic, functio...   \n",
      "\n",
      "                                     evidence_vector  \n",
      "0  [-0.024856949225068092, 0.0025685965083539486,...  \n",
      "1  [-0.010795524343848228, -0.01842009462416172, ...  \n",
      "2  [0.004620078019797802, 0.024167921394109726, 0...  \n",
      "3  [-0.013559743762016296, 0.016163170337677002, ...  \n",
      "4  [0.015882274135947227, -0.024261925369501114, ...  \n",
      "#####################################\n",
      "                                                    claim-1937  \\\n",
      "claim_text   Not only is there no scientific evidence that ...   \n",
      "claim_label                                           DISPUTED   \n",
      "evidences    [evidence-442946, evidence-1194317, evidence-1...   \n",
      "\n",
      "                                                     claim-126  \\\n",
      "claim_text   El Niño drove record highs in global temperatu...   \n",
      "claim_label                                            REFUTES   \n",
      "evidences                  [evidence-338219, evidence-1127398]   \n",
      "\n",
      "                                         claim-2510  \\\n",
      "claim_text   In 1946, PDO switched to a cool phase.   \n",
      "claim_label                                SUPPORTS   \n",
      "evidences        [evidence-530063, evidence-984887]   \n",
      "\n",
      "                                                    claim-2021  \\\n",
      "claim_text   Weather Channel co-founder John Coleman provid...   \n",
      "claim_label                                           DISPUTED   \n",
      "evidences    [evidence-1177431, evidence-782448, evidence-5...   \n",
      "\n",
      "                                                    claim-2449  \\\n",
      "claim_text   \"January 2008 capped a 12 month period of glob...   \n",
      "claim_label                                    NOT_ENOUGH_INFO   \n",
      "evidences    [evidence-1010750, evidence-91661, evidence-72...   \n",
      "\n",
      "                                                     claim-851  \\\n",
      "claim_text   The last time the planet was even four degrees...   \n",
      "claim_label                                    NOT_ENOUGH_INFO   \n",
      "evidences    [evidence-226174, evidence-1049316, evidence-3...   \n",
      "\n",
      "                                                    claim-2773  \\\n",
      "claim_text   Tree-ring proxy reconstructions are reliable b...   \n",
      "claim_label                                           DISPUTED   \n",
      "evidences                   [evidence-974673, evidence-602109]   \n",
      "\n",
      "                                                     claim-949  \\\n",
      "claim_text   Under the most ambitious scenarios, they found...   \n",
      "claim_label                                           DISPUTED   \n",
      "evidences    [evidence-707654, evidence-28478, evidence-491...   \n",
      "\n",
      "                                                    claim-1019  \\\n",
      "claim_text   An additional kick was supplied by an El Niño ...   \n",
      "claim_label                                    NOT_ENOUGH_INFO   \n",
      "evidences    [evidence-863309, evidence-61462, evidence-639...   \n",
      "\n",
      "                                                    claim-2834  ...  \\\n",
      "claim_text   When stomata-derived CO2 (red) is compared to ...  ...   \n",
      "claim_label                                           SUPPORTS  ...   \n",
      "evidences                                    [evidence-439640]  ...   \n",
      "\n",
      "                                                    claim-2076  \\\n",
      "claim_text   Snowfall is increasing in the fall and winter ...   \n",
      "claim_label                                           SUPPORTS   \n",
      "evidences    [evidence-599766, evidence-895097, evidence-17...   \n",
      "\n",
      "                                                    claim-2508  \\\n",
      "claim_text   \"The Pacific Decadal Oscillation (PDO) is a te...   \n",
      "claim_label                                           SUPPORTS   \n",
      "evidences    [evidence-1208158, evidence-623139, evidence-4...   \n",
      "\n",
      "                                                    claim-2049  \\\n",
      "claim_text   The Millennium Drought starting in 1997 and en...   \n",
      "claim_label                                           SUPPORTS   \n",
      "evidences    [evidence-978133, evidence-906284, evidence-10...   \n",
      "\n",
      "                                                    claim-1333  \\\n",
      "claim_text   “The oceans will never become acid because the...   \n",
      "claim_label                                    NOT_ENOUGH_INFO   \n",
      "evidences    [evidence-1009038, evidence-864864, evidence-5...   \n",
      "\n",
      "                                                    claim-1316  \\\n",
      "claim_text   In pushing too hard for the case that global w...   \n",
      "claim_label                                    NOT_ENOUGH_INFO   \n",
      "evidences    [evidence-374377, evidence-984234, evidence-53...   \n",
      "\n",
      "                                                    claim-1504  \\\n",
      "claim_text   Climate scientists say that aspects of the cas...   \n",
      "claim_label                                           SUPPORTS   \n",
      "evidences    [evidence-1055682, evidence-1047356, evidence-...   \n",
      "\n",
      "                                                     claim-243  \\\n",
      "claim_text   In its 5th assessment report in 2013, the IPCC...   \n",
      "claim_label                                           SUPPORTS   \n",
      "evidences                                    [evidence-916755]   \n",
      "\n",
      "                                                    claim-2302  \\\n",
      "claim_text   Since the mid 1970s, global temperatures have ...   \n",
      "claim_label                                    NOT_ENOUGH_INFO   \n",
      "evidences    [evidence-403673, evidence-889933, evidence-11...   \n",
      "\n",
      "                                                     claim-502  \\\n",
      "claim_text   But abnormal temperature spikes in February an...   \n",
      "claim_label                                    NOT_ENOUGH_INFO   \n",
      "evidences    [evidence-97375, evidence-562427, evidence-521...   \n",
      "\n",
      "                                                    claim-3093  \n",
      "claim_text   Sending oscillating microwaves from an antenna...  \n",
      "claim_label                                           SUPPORTS  \n",
      "evidences    [evidence-971105, evidence-457769, evidence-29...  \n",
      "\n",
      "[3 rows x 1228 columns]\n",
      "                                                     claim-752  \\\n",
      "claim_text   [South Australia] has the most expensive elect...   \n",
      "claim_label                                           SUPPORTS   \n",
      "evidences                    [evidence-67732, evidence-572512]   \n",
      "\n",
      "                                                     claim-375  \\\n",
      "claim_text   when 3 per cent of total annual global emissio...   \n",
      "claim_label                                    NOT_ENOUGH_INFO   \n",
      "evidences    [evidence-996421, evidence-1080858, evidence-2...   \n",
      "\n",
      "                                                    claim-1266  \\\n",
      "claim_text   This means that the world is now 1C warmer tha...   \n",
      "claim_label                                           SUPPORTS   \n",
      "evidences                   [evidence-889933, evidence-694262]   \n",
      "\n",
      "                                                     claim-871  \\\n",
      "claim_text   “As it happens, Zika may also be a good model ...   \n",
      "claim_label                                    NOT_ENOUGH_INFO   \n",
      "evidences    [evidence-422399, evidence-702226, evidence-28...   \n",
      "\n",
      "                                                    claim-2164  \\\n",
      "claim_text   Greenland has only lost a tiny fraction of its...   \n",
      "claim_label                                            REFUTES   \n",
      "evidences    [evidence-52981, evidence-264761, evidence-947...   \n",
      "\n",
      "                                                    claim-1607  \\\n",
      "claim_text                   CO2 limits won't cool the planet.   \n",
      "claim_label                                    NOT_ENOUGH_INFO   \n",
      "evidences    [evidence-913997, evidence-955328, evidence-40...   \n",
      "\n",
      "                                                     claim-761  \\\n",
      "claim_text   [Riebesell] is a world authority on the topic ...   \n",
      "claim_label                                    NOT_ENOUGH_INFO   \n",
      "evidences    [evidence-1129386, evidence-456747, evidence-6...   \n",
      "\n",
      "                                                    claim-1718  \\\n",
      "claim_text   The actual data show high northern latitudes a...   \n",
      "claim_label                                           SUPPORTS   \n",
      "evidences                  [evidence-857561, evidence-1150493]   \n",
      "\n",
      "                                                    claim-1273  \\\n",
      "claim_text   The rapid changes in the climate may have prof...   \n",
      "claim_label                                           SUPPORTS   \n",
      "evidences    [evidence-659559, evidence-181656, evidence-49...   \n",
      "\n",
      "                                                    claim-1786  ...  \\\n",
      "claim_text   CFCs contribute to global waerming at a small ...  ...   \n",
      "claim_label                                            REFUTES  ...   \n",
      "evidences    [evidence-845527, evidence-105411, evidence-32...  ...   \n",
      "\n",
      "                                                     claim-530  \\\n",
      "claim_text   South Australia is winning: it has the most un...   \n",
      "claim_label                                           SUPPORTS   \n",
      "evidences                                     [evidence-67732]   \n",
      "\n",
      "                                                    claim-2979  \\\n",
      "claim_text   Water vapor helps trap heat, and is a far the ...   \n",
      "claim_label                                           SUPPORTS   \n",
      "evidences                   [evidence-909112, evidence-706949]   \n",
      "\n",
      "                                                     claim-665  \\\n",
      "claim_text   many scientists were surprised when other rese...   \n",
      "claim_label                                    NOT_ENOUGH_INFO   \n",
      "evidences    [evidence-1105120, evidence-143437, evidence-1...   \n",
      "\n",
      "                                                     claim-199  \\\n",
      "claim_text   In the past, warming has never been a threat t...   \n",
      "claim_label                                            REFUTES   \n",
      "evidences                   [evidence-255653, evidence-817833]   \n",
      "\n",
      "                                                     claim-490  \\\n",
      "claim_text   IPCC report warning last week the world is “no...   \n",
      "claim_label                                           SUPPORTS   \n",
      "evidences    [evidence-225934, evidence-432573, evidence-10...   \n",
      "\n",
      "                                                    claim-2400  \\\n",
      "claim_text   'To suddenly label CO2 as a \"pollutant\" is a d...   \n",
      "claim_label                                            REFUTES   \n",
      "evidences    [evidence-409365, evidence-127519, evidence-85...   \n",
      "\n",
      "                                                     claim-204  \\\n",
      "claim_text   after a natural orbitally driven warming, atmo...   \n",
      "claim_label                                    NOT_ENOUGH_INFO   \n",
      "evidences    [evidence-368192, evidence-261690, evidence-20...   \n",
      "\n",
      "                                                    claim-1426  \\\n",
      "claim_text   Many of the world’s coral reefs are already ba...   \n",
      "claim_label                                    NOT_ENOUGH_INFO   \n",
      "evidences    [evidence-1124018, evidence-995813, evidence-1...   \n",
      "\n",
      "                                                     claim-698  \\\n",
      "claim_text   A recent study led by Lawrence Livermore Natio...   \n",
      "claim_label                                            REFUTES   \n",
      "evidences                                    [evidence-660755]   \n",
      "\n",
      "                                                    claim-1021  \n",
      "claim_text   The corals may save themselves, as many other ...  \n",
      "claim_label                                           SUPPORTS  \n",
      "evidences                  [evidence-242575, evidence-1175280]  \n",
      "\n",
      "[3 rows x 154 columns]\n",
      "                                                     claim-752  \\\n",
      "claim_text   [South Australia] has the most expensive elect...   \n",
      "claim_label                                    NOT_ENOUGH_INFO   \n",
      "evidences    [evidence-67732, evidence-572512, evidence-909...   \n",
      "\n",
      "                                                     claim-375  \\\n",
      "claim_text   when 3 per cent of total annual global emissio...   \n",
      "claim_label                                    NOT_ENOUGH_INFO   \n",
      "evidences    [evidence-832334, evidence-699212, evidence-10...   \n",
      "\n",
      "                                                    claim-1266  \\\n",
      "claim_text   This means that the world is now 1C warmer tha...   \n",
      "claim_label                                           SUPPORTS   \n",
      "evidences    [evidence-315434, evidence-198055, evidence-69...   \n",
      "\n",
      "                                                     claim-871  \\\n",
      "claim_text   “As it happens, Zika may also be a good model ...   \n",
      "claim_label                                            REFUTES   \n",
      "evidences    [evidence-303245, evidence-88449, evidence-385...   \n",
      "\n",
      "                                                    claim-2164  \\\n",
      "claim_text   Greenland has only lost a tiny fraction of its...   \n",
      "claim_label                                           DISPUTED   \n",
      "evidences    [evidence-947243, evidence-424102, evidence-91...   \n",
      "\n",
      "                                                    claim-1607  \\\n",
      "claim_text                   CO2 limits won't cool the planet.   \n",
      "claim_label                                    NOT_ENOUGH_INFO   \n",
      "evidences    [evidence-370378, evidence-947510, evidence-70...   \n",
      "\n",
      "                                                     claim-761  \\\n",
      "claim_text   [Riebesell] is a world authority on the topic ...   \n",
      "claim_label                                           SUPPORTS   \n",
      "evidences    [evidence-625922, evidence-421348, evidence-59...   \n",
      "\n",
      "                                                    claim-1718  \\\n",
      "claim_text   The actual data show high northern latitudes a...   \n",
      "claim_label                                           SUPPORTS   \n",
      "evidences    [evidence-28135, evidence-126025, evidence-115...   \n",
      "\n",
      "                                                    claim-1273  \\\n",
      "claim_text   The rapid changes in the climate may have prof...   \n",
      "claim_label                                           SUPPORTS   \n",
      "evidences    [evidence-350619, evidence-181656, evidence-78...   \n",
      "\n",
      "                                                    claim-1786  ...  \\\n",
      "claim_text   CFCs contribute to global waerming at a small ...  ...   \n",
      "claim_label                                            REFUTES  ...   \n",
      "evidences    [evidence-166597, evidence-237344, evidence-30...  ...   \n",
      "\n",
      "                                                     claim-530  \\\n",
      "claim_text   South Australia is winning: it has the most un...   \n",
      "claim_label                                           DISPUTED   \n",
      "evidences    [evidence-574843, evidence-396641, evidence-15...   \n",
      "\n",
      "                                                    claim-2979  \\\n",
      "claim_text   Water vapor helps trap heat, and is a far the ...   \n",
      "claim_label                                    NOT_ENOUGH_INFO   \n",
      "evidences    [evidence-306908, evidence-706949, evidence-10...   \n",
      "\n",
      "                                                     claim-665  \\\n",
      "claim_text   many scientists were surprised when other rese...   \n",
      "claim_label                                           SUPPORTS   \n",
      "evidences    [evidence-984463, evidence-114740, evidence-73...   \n",
      "\n",
      "                                                     claim-199  \\\n",
      "claim_text   In the past, warming has never been a threat t...   \n",
      "claim_label                                            REFUTES   \n",
      "evidences    [evidence-402399, evidence-610285, evidence-25...   \n",
      "\n",
      "                                                     claim-490  \\\n",
      "claim_text   IPCC report warning last week the world is “no...   \n",
      "claim_label                                    NOT_ENOUGH_INFO   \n",
      "evidences    [evidence-225934, evidence-432573, evidence-25...   \n",
      "\n",
      "                                                    claim-2400  \\\n",
      "claim_text   'To suddenly label CO2 as a \"pollutant\" is a d...   \n",
      "claim_label                                           SUPPORTS   \n",
      "evidences    [evidence-1022738, evidence-852573, evidence-4...   \n",
      "\n",
      "                                                     claim-204  \\\n",
      "claim_text   after a natural orbitally driven warming, atmo...   \n",
      "claim_label                                            REFUTES   \n",
      "evidences    [evidence-30998, evidence-926717, evidence-922...   \n",
      "\n",
      "                                                    claim-1426  \\\n",
      "claim_text   Many of the world’s coral reefs are already ba...   \n",
      "claim_label                                           SUPPORTS   \n",
      "evidences    [evidence-293637, evidence-305944, evidence-36...   \n",
      "\n",
      "                                                     claim-698  \\\n",
      "claim_text   A recent study led by Lawrence Livermore Natio...   \n",
      "claim_label                                            REFUTES   \n",
      "evidences    [evidence-519720, evidence-445144, evidence-82...   \n",
      "\n",
      "                                                    claim-1021  \n",
      "claim_text   The corals may save themselves, as many other ...  \n",
      "claim_label                                    NOT_ENOUGH_INFO  \n",
      "evidences    [evidence-128925, evidence-766771, evidence-81...  \n",
      "\n",
      "[3 rows x 154 columns]\n",
      "                                                   claim-2967  \\\n",
      "claim_text  The contribution of waste heat to the global c...   \n",
      "\n",
      "                                                    claim-979  \\\n",
      "claim_text  “Warm weather worsened the most recent five-ye...   \n",
      "\n",
      "                                                   claim-1609  \\\n",
      "claim_text  Greenland has only lost a tiny fraction of its...   \n",
      "\n",
      "                                                   claim-1020  \\\n",
      "claim_text  “The global reef crisis does not necessarily m...   \n",
      "\n",
      "                                                   claim-2599  \\\n",
      "claim_text  Small amounts of very active substances can ca...   \n",
      "\n",
      "                                                   claim-2110  \\\n",
      "claim_text  They changed the name from 'global warming' to...   \n",
      "\n",
      "                                                   claim-1135  \\\n",
      "claim_text  Scientists confirm a mass bleaching event on t...   \n",
      "\n",
      "                                                    claim-712  \\\n",
      "claim_text  “Instead of a three-foot increase in ocean lev...   \n",
      "\n",
      "                                                   claim-1307  \\\n",
      "claim_text  a new study by scientists at the Australian Re...   \n",
      "\n",
      "                                                    claim-148  ...  \\\n",
      "claim_text  Previous IPCC reports tended to assume that cl...  ...   \n",
      "\n",
      "                                                   claim-2561  \\\n",
      "claim_text  Observed sea levels are actually tracking at t...   \n",
      "\n",
      "                                                   claim-2219  \\\n",
      "claim_text  The increase in temperatures since 1975 is a c...   \n",
      "\n",
      "                                                   claim-1343  \\\n",
      "claim_text  roughly three-quarters of the tidal flood days...   \n",
      "\n",
      "                                                   claim-1351  \\\n",
      "claim_text  a marginally significant warming trend in the ...   \n",
      "\n",
      "                                                   claim-2347  \\\n",
      "claim_text  In truth, the overwhelming majority of climate...   \n",
      "\n",
      "                                                    claim-293  \\\n",
      "claim_text  When the measuring equipment gets old and need...   \n",
      "\n",
      "                                                    claim-910  \\\n",
      "claim_text  The cement, iron and steel, and petroleum refi...   \n",
      "\n",
      "                                                   claim-2815  \\\n",
      "claim_text  A new peer-reviewed study on Surface Warming a...   \n",
      "\n",
      "                                                   claim-1652  \\\n",
      "claim_text  The strong CO2 effect has been observed by man...   \n",
      "\n",
      "                                                   claim-1212  \n",
      "claim_text  (In technical lingo, the so-called social cost...  \n",
      "\n",
      "[1 rows x 153 columns]\n",
      "          key                                              value\n",
      "0  evidence-0  John Bennet Lawes, English entrepreneur and ag...\n",
      "1  evidence-1  Lindberg began his professional career at the ...\n",
      "2  evidence-2  ``Boston (Ladies of Cambridge)'' by Vampire We...\n",
      "3  evidence-3  Gerald Francis Goyer (born October 20, 1936) w...\n",
      "4  evidence-4  He detected abnormalities of oxytocinergic fun...\n"
     ]
    }
   ],
   "source": [
    "# print head of the dataframes\n",
    "print(train_df.head())\n",
    "print(dev_df.head())\n",
    "print(dev_baseline_df.head())\n",
    "print(test_df.head())\n",
    "print(evidence_df.head())\n",
    "print(\"#####################################\")\n",
    "print(original_train_df.head())\n",
    "print(original_dev_df.head())\n",
    "print(original_dev_baseline_df.head())\n",
    "print(original_test_df.head())\n",
    "print(original_evidence_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc52223",
   "metadata": {},
   "source": [
    "### Doc2Vec encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e79079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['john', 'bennet', 'lawes', 'english', 'entrepreneur', 'agricultural', 'scientist'], ['lindberg', 'began', 'professional', 'career', 'age', '16', 'eventually', 'moving', 'new', 'york', 'city', '1977'], ['boston', 'lady', 'cambridge', 'vampire', 'weekend'], ['gerald', 'francis', 'goyer', 'born', 'october', '20', '1936', 'professional', 'ice', 'hockey', 'player', 'played', '40', 'game', 'national', 'hockey', 'league'], ['detected', 'abnormality', 'oxytocinergic', 'function', 'schizoaffective', 'mania', 'postpartum', 'psychosis', 'ect', 'modified', 'oxytocin', 'release']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Bill\n",
      "[nltk_data]     Zhu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "2025-05-13 11:25:20,985 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n5,w5,mc2,s0.001,t5>', 'datetime': '2025-05-13T11:25:20.985943', 'gensim': '4.3.3', 'python': '3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'created'}\n",
      "2025-05-13 11:25:21,075 : INFO : collecting all words and their counts\n",
      "2025-05-13 11:25:21,076 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2025-05-13 11:25:21,122 : INFO : PROGRESS: at example #10000, processed 120676 words (2640069 words/s), 27728 word types, 10000 tags\n",
      "2025-05-13 11:25:21,164 : INFO : PROGRESS: at example #20000, processed 240194 words (2923122 words/s), 43858 word types, 20000 tags\n",
      "2025-05-13 11:25:21,199 : INFO : PROGRESS: at example #30000, processed 359019 words (3496930 words/s), 57343 word types, 30000 tags\n",
      "2025-05-13 11:25:21,234 : INFO : PROGRESS: at example #40000, processed 478939 words (3518418 words/s), 69300 word types, 40000 tags\n",
      "2025-05-13 11:25:21,280 : INFO : PROGRESS: at example #50000, processed 598410 words (2678800 words/s), 80311 word types, 50000 tags\n",
      "2025-05-13 11:25:21,320 : INFO : PROGRESS: at example #60000, processed 718525 words (3012764 words/s), 90869 word types, 60000 tags\n",
      "2025-05-13 11:25:21,365 : INFO : PROGRESS: at example #70000, processed 839403 words (2714328 words/s), 100759 word types, 70000 tags\n",
      "2025-05-13 11:25:21,404 : INFO : PROGRESS: at example #80000, processed 959777 words (3216999 words/s), 110152 word types, 80000 tags\n",
      "2025-05-13 11:25:21,444 : INFO : PROGRESS: at example #90000, processed 1079296 words (3019704 words/s), 119182 word types, 90000 tags\n",
      "2025-05-13 11:25:21,481 : INFO : PROGRESS: at example #100000, processed 1197868 words (3240601 words/s), 127854 word types, 100000 tags\n",
      "2025-05-13 11:25:21,520 : INFO : PROGRESS: at example #110000, processed 1317774 words (3140224 words/s), 136460 word types, 110000 tags\n",
      "2025-05-13 11:25:21,557 : INFO : PROGRESS: at example #120000, processed 1438061 words (3311903 words/s), 144617 word types, 120000 tags\n",
      "2025-05-13 11:25:21,599 : INFO : PROGRESS: at example #130000, processed 1557678 words (2908648 words/s), 152363 word types, 130000 tags\n",
      "2025-05-13 11:25:21,637 : INFO : PROGRESS: at example #140000, processed 1678230 words (3323555 words/s), 160124 word types, 140000 tags\n",
      "2025-05-13 11:25:21,680 : INFO : PROGRESS: at example #150000, processed 1798352 words (2845191 words/s), 167739 word types, 150000 tags\n",
      "2025-05-13 11:25:21,733 : INFO : PROGRESS: at example #160000, processed 1916581 words (2236855 words/s), 175034 word types, 160000 tags\n",
      "2025-05-13 11:25:21,779 : INFO : PROGRESS: at example #170000, processed 2035210 words (2641741 words/s), 182318 word types, 170000 tags\n",
      "2025-05-13 11:25:21,831 : INFO : PROGRESS: at example #180000, processed 2154681 words (2362118 words/s), 189431 word types, 180000 tags\n",
      "2025-05-13 11:25:21,874 : INFO : PROGRESS: at example #190000, processed 2275588 words (2825735 words/s), 196332 word types, 190000 tags\n",
      "2025-05-13 11:25:21,914 : INFO : PROGRESS: at example #200000, processed 2395625 words (3098368 words/s), 202992 word types, 200000 tags\n",
      "2025-05-13 11:25:21,950 : INFO : PROGRESS: at example #210000, processed 2515068 words (3405020 words/s), 209738 word types, 210000 tags\n",
      "2025-05-13 11:25:21,989 : INFO : PROGRESS: at example #220000, processed 2634717 words (3115705 words/s), 216276 word types, 220000 tags\n",
      "2025-05-13 11:25:22,027 : INFO : PROGRESS: at example #230000, processed 2755916 words (3270839 words/s), 222881 word types, 230000 tags\n",
      "2025-05-13 11:25:22,065 : INFO : PROGRESS: at example #240000, processed 2875137 words (3120829 words/s), 229130 word types, 240000 tags\n",
      "2025-05-13 11:25:22,107 : INFO : PROGRESS: at example #250000, processed 2995707 words (2909423 words/s), 235515 word types, 250000 tags\n",
      "2025-05-13 11:25:22,148 : INFO : PROGRESS: at example #260000, processed 3115121 words (3008401 words/s), 241633 word types, 260000 tags\n",
      "2025-05-13 11:25:22,188 : INFO : PROGRESS: at example #270000, processed 3234992 words (3055166 words/s), 247879 word types, 270000 tags\n",
      "2025-05-13 11:25:22,225 : INFO : PROGRESS: at example #280000, processed 3355019 words (3276382 words/s), 254011 word types, 280000 tags\n",
      "2025-05-13 11:25:22,262 : INFO : PROGRESS: at example #290000, processed 3474616 words (3294991 words/s), 259957 word types, 290000 tags\n",
      "2025-05-13 11:25:22,300 : INFO : PROGRESS: at example #300000, processed 3595198 words (3303743 words/s), 265893 word types, 300000 tags\n",
      "2025-05-13 11:25:22,337 : INFO : PROGRESS: at example #310000, processed 3716062 words (3280853 words/s), 271614 word types, 310000 tags\n",
      "2025-05-13 11:25:22,375 : INFO : PROGRESS: at example #320000, processed 3835906 words (3252352 words/s), 277440 word types, 320000 tags\n",
      "2025-05-13 11:25:22,412 : INFO : PROGRESS: at example #330000, processed 3955196 words (3299469 words/s), 282970 word types, 330000 tags\n",
      "2025-05-13 11:25:22,448 : INFO : PROGRESS: at example #340000, processed 4075244 words (3359357 words/s), 288589 word types, 340000 tags\n",
      "2025-05-13 11:25:22,503 : INFO : PROGRESS: at example #350000, processed 4195168 words (2241595 words/s), 294106 word types, 350000 tags\n",
      "2025-05-13 11:25:22,539 : INFO : PROGRESS: at example #360000, processed 4315316 words (3354477 words/s), 299591 word types, 360000 tags\n",
      "2025-05-13 11:25:22,576 : INFO : PROGRESS: at example #370000, processed 4435601 words (3327698 words/s), 305016 word types, 370000 tags\n",
      "2025-05-13 11:25:22,613 : INFO : PROGRESS: at example #380000, processed 4555459 words (3273923 words/s), 310290 word types, 380000 tags\n",
      "2025-05-13 11:25:22,650 : INFO : PROGRESS: at example #390000, processed 4676046 words (3439211 words/s), 315551 word types, 390000 tags\n",
      "2025-05-13 11:25:23,925 : INFO : PROGRESS: at example #400000, processed 4795942 words (94015 words/s), 320829 word types, 400000 tags\n",
      "2025-05-13 11:25:23,964 : INFO : PROGRESS: at example #410000, processed 4915733 words (3174045 words/s), 325968 word types, 410000 tags\n",
      "2025-05-13 11:25:24,003 : INFO : PROGRESS: at example #420000, processed 5037499 words (3212111 words/s), 331197 word types, 420000 tags\n",
      "2025-05-13 11:25:24,041 : INFO : PROGRESS: at example #430000, processed 5158388 words (3242756 words/s), 336493 word types, 430000 tags\n",
      "2025-05-13 11:25:24,078 : INFO : PROGRESS: at example #440000, processed 5279413 words (3308411 words/s), 341673 word types, 440000 tags\n",
      "2025-05-13 11:25:24,114 : INFO : PROGRESS: at example #450000, processed 5398830 words (3405919 words/s), 346597 word types, 450000 tags\n",
      "2025-05-13 11:25:24,161 : INFO : PROGRESS: at example #460000, processed 5518593 words (2595255 words/s), 351625 word types, 460000 tags\n",
      "2025-05-13 11:25:24,203 : INFO : PROGRESS: at example #470000, processed 5638419 words (2884995 words/s), 356596 word types, 470000 tags\n",
      "2025-05-13 11:25:24,245 : INFO : PROGRESS: at example #480000, processed 5758247 words (2948755 words/s), 361626 word types, 480000 tags\n",
      "2025-05-13 11:25:24,282 : INFO : PROGRESS: at example #490000, processed 5877508 words (3264535 words/s), 366340 word types, 490000 tags\n",
      "2025-05-13 11:25:24,319 : INFO : PROGRESS: at example #500000, processed 5997429 words (3345589 words/s), 371093 word types, 500000 tags\n",
      "2025-05-13 11:25:24,357 : INFO : PROGRESS: at example #510000, processed 6119222 words (3256845 words/s), 375933 word types, 510000 tags\n",
      "2025-05-13 11:25:24,394 : INFO : PROGRESS: at example #520000, processed 6240127 words (3288222 words/s), 380658 word types, 520000 tags\n",
      "2025-05-13 11:25:24,432 : INFO : PROGRESS: at example #530000, processed 6360403 words (3302870 words/s), 385264 word types, 530000 tags\n",
      "2025-05-13 11:25:24,468 : INFO : PROGRESS: at example #540000, processed 6480034 words (3322658 words/s), 389788 word types, 540000 tags\n",
      "2025-05-13 11:25:24,505 : INFO : PROGRESS: at example #550000, processed 6598689 words (3346259 words/s), 394381 word types, 550000 tags\n",
      "2025-05-13 11:25:24,540 : INFO : PROGRESS: at example #560000, processed 6718722 words (3432907 words/s), 398966 word types, 560000 tags\n",
      "2025-05-13 11:25:24,578 : INFO : PROGRESS: at example #570000, processed 6839198 words (3224309 words/s), 403639 word types, 570000 tags\n",
      "2025-05-13 11:25:24,615 : INFO : PROGRESS: at example #580000, processed 6958960 words (3296703 words/s), 408150 word types, 580000 tags\n",
      "2025-05-13 11:25:24,654 : INFO : PROGRESS: at example #590000, processed 7079012 words (3189335 words/s), 412747 word types, 590000 tags\n",
      "2025-05-13 11:25:24,692 : INFO : PROGRESS: at example #600000, processed 7199804 words (3255217 words/s), 417325 word types, 600000 tags\n",
      "2025-05-13 11:25:24,731 : INFO : PROGRESS: at example #610000, processed 7320445 words (3129614 words/s), 421836 word types, 610000 tags\n",
      "2025-05-13 11:25:24,767 : INFO : PROGRESS: at example #620000, processed 7440330 words (3325068 words/s), 426323 word types, 620000 tags\n",
      "2025-05-13 11:25:24,803 : INFO : PROGRESS: at example #630000, processed 7560051 words (3434918 words/s), 430707 word types, 630000 tags\n",
      "2025-05-13 11:25:24,841 : INFO : PROGRESS: at example #640000, processed 7680438 words (3176446 words/s), 435159 word types, 640000 tags\n",
      "2025-05-13 11:25:24,879 : INFO : PROGRESS: at example #650000, processed 7800599 words (3262717 words/s), 439664 word types, 650000 tags\n",
      "2025-05-13 11:25:24,917 : INFO : PROGRESS: at example #660000, processed 7919999 words (3218103 words/s), 443847 word types, 660000 tags\n",
      "2025-05-13 11:25:24,954 : INFO : PROGRESS: at example #670000, processed 8039703 words (3228036 words/s), 448242 word types, 670000 tags\n",
      "2025-05-13 11:25:24,993 : INFO : PROGRESS: at example #680000, processed 8159259 words (3198009 words/s), 452426 word types, 680000 tags\n",
      "2025-05-13 11:25:25,031 : INFO : PROGRESS: at example #690000, processed 8280040 words (3205738 words/s), 456754 word types, 690000 tags\n",
      "2025-05-13 11:25:25,093 : INFO : PROGRESS: at example #700000, processed 8399573 words (1968768 words/s), 461029 word types, 700000 tags\n",
      "2025-05-13 11:25:25,130 : INFO : PROGRESS: at example #710000, processed 8520157 words (3290132 words/s), 465264 word types, 710000 tags\n",
      "2025-05-13 11:25:25,167 : INFO : PROGRESS: at example #720000, processed 8639496 words (3319324 words/s), 469568 word types, 720000 tags\n",
      "2025-05-13 11:25:25,205 : INFO : PROGRESS: at example #730000, processed 8758406 words (3189201 words/s), 473805 word types, 730000 tags\n",
      "2025-05-13 11:25:25,244 : INFO : PROGRESS: at example #740000, processed 8878362 words (3099918 words/s), 477974 word types, 740000 tags\n",
      "2025-05-13 11:25:25,284 : INFO : PROGRESS: at example #750000, processed 8998393 words (3038813 words/s), 482303 word types, 750000 tags\n",
      "2025-05-13 11:25:25,321 : INFO : PROGRESS: at example #760000, processed 9116806 words (3348802 words/s), 486519 word types, 760000 tags\n",
      "2025-05-13 11:25:25,358 : INFO : PROGRESS: at example #770000, processed 9236457 words (3249425 words/s), 490658 word types, 770000 tags\n",
      "2025-05-13 11:25:25,397 : INFO : PROGRESS: at example #780000, processed 9355964 words (3187235 words/s), 494641 word types, 780000 tags\n",
      "2025-05-13 11:25:25,434 : INFO : PROGRESS: at example #790000, processed 9477053 words (3339004 words/s), 498650 word types, 790000 tags\n",
      "2025-05-13 11:25:25,471 : INFO : PROGRESS: at example #800000, processed 9596893 words (3272555 words/s), 502845 word types, 800000 tags\n",
      "2025-05-13 11:25:25,510 : INFO : PROGRESS: at example #810000, processed 9717096 words (3163894 words/s), 506844 word types, 810000 tags\n",
      "2025-05-13 11:25:25,548 : INFO : PROGRESS: at example #820000, processed 9836633 words (3229533 words/s), 510936 word types, 820000 tags\n",
      "2025-05-13 11:25:25,587 : INFO : PROGRESS: at example #830000, processed 9958022 words (3161632 words/s), 515069 word types, 830000 tags\n",
      "2025-05-13 11:25:25,626 : INFO : PROGRESS: at example #840000, processed 10078157 words (3158488 words/s), 519173 word types, 840000 tags\n",
      "2025-05-13 11:25:25,663 : INFO : PROGRESS: at example #850000, processed 10198196 words (3258290 words/s), 523144 word types, 850000 tags\n",
      "2025-05-13 11:25:25,703 : INFO : PROGRESS: at example #860000, processed 10317199 words (3081127 words/s), 526998 word types, 860000 tags\n",
      "2025-05-13 11:25:25,741 : INFO : PROGRESS: at example #870000, processed 10437780 words (3209211 words/s), 530971 word types, 870000 tags\n",
      "2025-05-13 11:25:25,779 : INFO : PROGRESS: at example #880000, processed 10558929 words (3286885 words/s), 535102 word types, 880000 tags\n",
      "2025-05-13 11:25:25,817 : INFO : PROGRESS: at example #890000, processed 10678055 words (3216891 words/s), 538908 word types, 890000 tags\n",
      "2025-05-13 11:25:25,855 : INFO : PROGRESS: at example #900000, processed 10798300 words (3249311 words/s), 542759 word types, 900000 tags\n",
      "2025-05-13 11:25:25,892 : INFO : PROGRESS: at example #910000, processed 10917526 words (3202546 words/s), 546525 word types, 910000 tags\n",
      "2025-05-13 11:25:25,931 : INFO : PROGRESS: at example #920000, processed 11037774 words (3225173 words/s), 550239 word types, 920000 tags\n",
      "2025-05-13 11:25:25,970 : INFO : PROGRESS: at example #930000, processed 11157394 words (3138792 words/s), 554016 word types, 930000 tags\n",
      "2025-05-13 11:25:26,011 : INFO : PROGRESS: at example #940000, processed 11277590 words (2907540 words/s), 557933 word types, 940000 tags\n",
      "2025-05-13 11:25:26,050 : INFO : PROGRESS: at example #950000, processed 11398074 words (3231190 words/s), 561749 word types, 950000 tags\n",
      "2025-05-13 11:25:26,088 : INFO : PROGRESS: at example #960000, processed 11519078 words (3244527 words/s), 565618 word types, 960000 tags\n",
      "2025-05-13 11:25:26,127 : INFO : PROGRESS: at example #970000, processed 11639065 words (3100255 words/s), 569347 word types, 970000 tags\n",
      "2025-05-13 11:25:26,165 : INFO : PROGRESS: at example #980000, processed 11759008 words (3231127 words/s), 573112 word types, 980000 tags\n",
      "2025-05-13 11:25:26,203 : INFO : PROGRESS: at example #990000, processed 11879151 words (3195386 words/s), 576803 word types, 990000 tags\n",
      "2025-05-13 11:25:26,241 : INFO : PROGRESS: at example #1000000, processed 11998848 words (3247156 words/s), 580340 word types, 1000000 tags\n",
      "2025-05-13 11:25:26,279 : INFO : PROGRESS: at example #1010000, processed 12118565 words (3222781 words/s), 583909 word types, 1010000 tags\n",
      "2025-05-13 11:25:26,316 : INFO : PROGRESS: at example #1020000, processed 12237966 words (3256192 words/s), 587654 word types, 1020000 tags\n",
      "2025-05-13 11:25:26,354 : INFO : PROGRESS: at example #1030000, processed 12356734 words (3225690 words/s), 591235 word types, 1030000 tags\n",
      "2025-05-13 11:25:26,393 : INFO : PROGRESS: at example #1040000, processed 12477045 words (3140361 words/s), 594912 word types, 1040000 tags\n",
      "2025-05-13 11:25:26,432 : INFO : PROGRESS: at example #1050000, processed 12596251 words (3168215 words/s), 598493 word types, 1050000 tags\n",
      "2025-05-13 11:25:26,474 : INFO : PROGRESS: at example #1060000, processed 12716168 words (2901241 words/s), 602108 word types, 1060000 tags\n",
      "2025-05-13 11:25:26,511 : INFO : PROGRESS: at example #1070000, processed 12836517 words (3261446 words/s), 605852 word types, 1070000 tags\n",
      "2025-05-13 11:25:26,549 : INFO : PROGRESS: at example #1080000, processed 12956117 words (3215641 words/s), 609493 word types, 1080000 tags\n",
      "2025-05-13 11:25:26,587 : INFO : PROGRESS: at example #1090000, processed 13075777 words (3265330 words/s), 613073 word types, 1090000 tags\n",
      "2025-05-13 11:25:26,625 : INFO : PROGRESS: at example #1100000, processed 13195021 words (3176113 words/s), 616689 word types, 1100000 tags\n",
      "2025-05-13 11:25:26,663 : INFO : PROGRESS: at example #1110000, processed 13315248 words (3250432 words/s), 620182 word types, 1110000 tags\n",
      "2025-05-13 11:25:26,701 : INFO : PROGRESS: at example #1120000, processed 13434078 words (3168580 words/s), 623708 word types, 1120000 tags\n",
      "2025-05-13 11:25:26,741 : INFO : PROGRESS: at example #1130000, processed 13553787 words (3106170 words/s), 627327 word types, 1130000 tags\n",
      "2025-05-13 11:25:26,787 : INFO : PROGRESS: at example #1140000, processed 13672382 words (2604365 words/s), 630833 word types, 1140000 tags\n",
      "2025-05-13 11:25:26,834 : INFO : PROGRESS: at example #1150000, processed 13793263 words (2605087 words/s), 634387 word types, 1150000 tags\n",
      "2025-05-13 11:25:26,872 : INFO : PROGRESS: at example #1160000, processed 13913820 words (3262565 words/s), 637904 word types, 1160000 tags\n",
      "2025-05-13 11:25:26,910 : INFO : PROGRESS: at example #1170000, processed 14032626 words (3143797 words/s), 641460 word types, 1170000 tags\n",
      "2025-05-13 11:25:26,949 : INFO : PROGRESS: at example #1180000, processed 14152497 words (3119406 words/s), 644829 word types, 1180000 tags\n",
      "2025-05-13 11:25:26,992 : INFO : PROGRESS: at example #1190000, processed 14271938 words (2880004 words/s), 648255 word types, 1190000 tags\n",
      "2025-05-13 11:25:27,032 : INFO : PROGRESS: at example #1200000, processed 14391799 words (3009533 words/s), 651687 word types, 1200000 tags\n",
      "2025-05-13 11:25:30,972 : INFO : collected 654822 word types and 1208827 unique tags from a corpus of 1208827 examples and 14497168 words\n",
      "2025-05-13 11:25:30,973 : INFO : Creating a fresh vocabulary\n",
      "2025-05-13 11:25:31,689 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=2 retains 250941 unique words (38.32% of original 654822, drops 403881)', 'datetime': '2025-05-13T11:25:31.689667', 'gensim': '4.3.3', 'python': '3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'prepare_vocab'}\n",
      "2025-05-13 11:25:31,690 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 14093287 word corpus (97.21% of original 14497168, drops 403881)', 'datetime': '2025-05-13T11:25:31.690659', 'gensim': '4.3.3', 'python': '3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'prepare_vocab'}\n",
      "2025-05-13 11:25:32,652 : INFO : deleting the raw counts dictionary of 654822 items\n",
      "2025-05-13 11:25:32,665 : INFO : sample=0.001 downsamples 8 most-common words\n",
      "2025-05-13 11:25:32,665 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 14024062.784275934 word corpus (99.5%% of prior 14093287)', 'datetime': '2025-05-13T11:25:32.665795', 'gensim': '4.3.3', 'python': '3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'prepare_vocab'}\n",
      "2025-05-13 11:25:34,049 : INFO : estimated required memory for 250941 words and 50 dimensions: 709377700 bytes\n",
      "2025-05-13 11:25:34,050 : INFO : resetting layer weights\n",
      "2025-05-13 11:25:34,307 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 5 workers on 250941 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2025-05-13T11:25:34.307058', 'gensim': '4.3.3', 'python': '3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'train'}\n",
      "2025-05-13 11:25:35,339 : INFO : EPOCH 0 - PROGRESS: at 1.45% examples, 214888 words/s, in_qsize 10, out_qsize 0\n",
      "2025-05-13 11:25:36,422 : INFO : EPOCH 0 - PROGRESS: at 3.18% examples, 229159 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:25:37,448 : INFO : EPOCH 0 - PROGRESS: at 4.90% examples, 237801 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:25:38,511 : INFO : EPOCH 0 - PROGRESS: at 6.61% examples, 240089 words/s, in_qsize 10, out_qsize 0\n",
      "2025-05-13 11:25:39,572 : INFO : EPOCH 0 - PROGRESS: at 8.35% examples, 241601 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:25:40,611 : INFO : EPOCH 0 - PROGRESS: at 10.07% examples, 243423 words/s, in_qsize 10, out_qsize 0\n",
      "2025-05-13 11:25:41,660 : INFO : EPOCH 0 - PROGRESS: at 11.79% examples, 244342 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:25:42,699 : INFO : EPOCH 0 - PROGRESS: at 13.53% examples, 245393 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:25:43,741 : INFO : EPOCH 0 - PROGRESS: at 15.26% examples, 246097 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:25:44,796 : INFO : EPOCH 0 - PROGRESS: at 16.98% examples, 246347 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:25:45,833 : INFO : EPOCH 0 - PROGRESS: at 18.70% examples, 246970 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:25:46,859 : INFO : EPOCH 0 - PROGRESS: at 20.42% examples, 247694 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:25:47,883 : INFO : EPOCH 0 - PROGRESS: at 22.08% examples, 247582 words/s, in_qsize 10, out_qsize 0\n",
      "2025-05-13 11:25:48,984 : INFO : EPOCH 0 - PROGRESS: at 23.80% examples, 246879 words/s, in_qsize 10, out_qsize 0\n",
      "2025-05-13 11:25:50,045 : INFO : EPOCH 0 - PROGRESS: at 25.45% examples, 246240 words/s, in_qsize 10, out_qsize 0\n",
      "2025-05-13 11:25:51,092 : INFO : EPOCH 0 - PROGRESS: at 27.11% examples, 245908 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:25:52,118 : INFO : EPOCH 0 - PROGRESS: at 28.62% examples, 244700 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:25:53,176 : INFO : EPOCH 0 - PROGRESS: at 30.34% examples, 244896 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:25:54,263 : INFO : EPOCH 0 - PROGRESS: at 32.06% examples, 244715 words/s, in_qsize 10, out_qsize 0\n",
      "2025-05-13 11:25:55,341 : INFO : EPOCH 0 - PROGRESS: at 33.78% examples, 244649 words/s, in_qsize 10, out_qsize 0\n",
      "2025-05-13 11:25:56,346 : INFO : EPOCH 0 - PROGRESS: at 35.35% examples, 244448 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:25:57,385 : INFO : EPOCH 0 - PROGRESS: at 36.86% examples, 243455 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:25:58,480 : INFO : EPOCH 0 - PROGRESS: at 38.59% examples, 243298 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:25:59,543 : INFO : EPOCH 0 - PROGRESS: at 40.32% examples, 243448 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:26:00,574 : INFO : EPOCH 0 - PROGRESS: at 41.97% examples, 243489 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:26:01,583 : INFO : EPOCH 0 - PROGRESS: at 43.61% examples, 243718 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:26:02,620 : INFO : EPOCH 0 - PROGRESS: at 45.20% examples, 243328 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:26:03,627 : INFO : EPOCH 0 - PROGRESS: at 46.78% examples, 243212 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:26:04,691 : INFO : EPOCH 0 - PROGRESS: at 48.50% examples, 243334 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:26:05,741 : INFO : EPOCH 0 - PROGRESS: at 50.22% examples, 243554 words/s, in_qsize 10, out_qsize 0\n",
      "2025-05-13 11:26:06,811 : INFO : EPOCH 0 - PROGRESS: at 51.94% examples, 243613 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:26:07,853 : INFO : EPOCH 0 - PROGRESS: at 53.66% examples, 243871 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:26:08,876 : INFO : EPOCH 0 - PROGRESS: at 55.39% examples, 244249 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:26:09,915 : INFO : EPOCH 0 - PROGRESS: at 57.11% examples, 244490 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:26:10,953 : INFO : EPOCH 0 - PROGRESS: at 58.76% examples, 244443 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:26:12,010 : INFO : EPOCH 0 - PROGRESS: at 60.29% examples, 243713 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:26:13,052 : INFO : EPOCH 0 - PROGRESS: at 61.87% examples, 243391 words/s, in_qsize 10, out_qsize 0\n",
      "2025-05-13 11:26:14,059 : INFO : EPOCH 0 - PROGRESS: at 63.47% examples, 243300 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:26:15,075 : INFO : EPOCH 0 - PROGRESS: at 65.12% examples, 243423 words/s, in_qsize 10, out_qsize 0\n",
      "2025-05-13 11:26:16,144 : INFO : EPOCH 0 - PROGRESS: at 66.84% examples, 243478 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:26:17,145 : INFO : EPOCH 0 - PROGRESS: at 68.49% examples, 243671 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:26:18,148 : INFO : EPOCH 0 - PROGRESS: at 69.87% examples, 242877 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:26:19,149 : INFO : EPOCH 0 - PROGRESS: at 71.39% examples, 242610 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:26:20,151 : INFO : EPOCH 0 - PROGRESS: at 72.82% examples, 242112 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:26:21,226 : INFO : EPOCH 0 - PROGRESS: at 74.55% examples, 242162 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:26:22,289 : INFO : EPOCH 0 - PROGRESS: at 76.28% examples, 242275 words/s, in_qsize 10, out_qsize 0\n",
      "2025-05-13 11:26:23,333 : INFO : EPOCH 0 - PROGRESS: at 78.00% examples, 242468 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:26:24,372 : INFO : EPOCH 0 - PROGRESS: at 79.71% examples, 242681 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:26:25,426 : INFO : EPOCH 0 - PROGRESS: at 81.43% examples, 242809 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:26:26,486 : INFO : EPOCH 0 - PROGRESS: at 83.16% examples, 242913 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:26:27,512 : INFO : EPOCH 0 - PROGRESS: at 84.82% examples, 242963 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:26:28,527 : INFO : EPOCH 0 - PROGRESS: at 86.48% examples, 243069 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:26:29,528 : INFO : EPOCH 0 - PROGRESS: at 88.14% examples, 243223 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:26:30,553 : INFO : EPOCH 0 - PROGRESS: at 89.86% examples, 243453 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:26:31,570 : INFO : EPOCH 0 - PROGRESS: at 91.45% examples, 243351 words/s, in_qsize 10, out_qsize 0\n",
      "2025-05-13 11:26:32,672 : INFO : EPOCH 0 - PROGRESS: at 93.11% examples, 243074 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:26:33,685 : INFO : EPOCH 0 - PROGRESS: at 94.77% examples, 243174 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:26:34,703 : INFO : EPOCH 0 - PROGRESS: at 96.21% examples, 242722 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:26:35,795 : INFO : EPOCH 0 - PROGRESS: at 97.94% examples, 242686 words/s, in_qsize 10, out_qsize 0\n",
      "2025-05-13 11:26:36,858 : INFO : EPOCH 0 - PROGRESS: at 99.67% examples, 242756 words/s, in_qsize 5, out_qsize 0\n",
      "2025-05-13 11:26:36,930 : INFO : EPOCH 0: training on 14497168 raw words (15232696 effective words) took 62.6s, 243273 effective words/s\n",
      "2025-05-13 11:26:37,942 : INFO : EPOCH 1 - PROGRESS: at 1.58% examples, 239960 words/s, in_qsize 10, out_qsize 0\n",
      "2025-05-13 11:26:38,965 : INFO : EPOCH 1 - PROGRESS: at 3.45% examples, 258860 words/s, in_qsize 10, out_qsize 0\n",
      "2025-05-13 11:26:40,116 : INFO : EPOCH 1 - PROGRESS: at 5.24% examples, 250983 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:26:41,122 : INFO : EPOCH 1 - PROGRESS: at 7.03% examples, 255816 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:26:42,123 : INFO : EPOCH 1 - PROGRESS: at 8.76% examples, 257060 words/s, in_qsize 10, out_qsize 0\n",
      "2025-05-13 11:26:43,136 : INFO : EPOCH 1 - PROGRESS: at 10.49% examples, 257418 words/s, in_qsize 10, out_qsize 0\n",
      "2025-05-13 11:26:44,165 : INFO : EPOCH 1 - PROGRESS: at 12.14% examples, 255587 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:26:45,185 : INFO : EPOCH 1 - PROGRESS: at 13.88% examples, 255831 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:26:46,191 : INFO : EPOCH 1 - PROGRESS: at 15.60% examples, 256362 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:26:47,197 : INFO : EPOCH 1 - PROGRESS: at 17.33% examples, 256803 words/s, in_qsize 10, out_qsize 0\n",
      "2025-05-13 11:26:48,198 : INFO : EPOCH 1 - PROGRESS: at 19.11% examples, 258218 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:26:49,204 : INFO : EPOCH 1 - PROGRESS: at 20.77% examples, 257572 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:26:50,206 : INFO : EPOCH 1 - PROGRESS: at 22.56% examples, 258696 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:26:51,256 : INFO : EPOCH 1 - PROGRESS: at 24.42% examples, 259514 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:26:52,323 : INFO : EPOCH 1 - PROGRESS: at 26.21% examples, 259269 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:26:53,358 : INFO : EPOCH 1 - PROGRESS: at 27.86% examples, 258270 words/s, in_qsize 10, out_qsize 0\n",
      "2025-05-13 11:26:54,400 : INFO : EPOCH 1 - PROGRESS: at 29.38% examples, 256101 words/s, in_qsize 10, out_qsize 0\n",
      "2025-05-13 11:26:55,400 : INFO : EPOCH 1 - PROGRESS: at 31.03% examples, 255877 words/s, in_qsize 10, out_qsize 0\n",
      "2025-05-13 11:26:56,458 : INFO : EPOCH 1 - PROGRESS: at 32.75% examples, 255450 words/s, in_qsize 10, out_qsize 0\n",
      "2025-05-13 11:26:57,506 : INFO : EPOCH 1 - PROGRESS: at 34.47% examples, 255206 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:26:58,531 : INFO : EPOCH 1 - PROGRESS: at 36.17% examples, 255246 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:26:59,552 : INFO : EPOCH 1 - PROGRESS: at 37.83% examples, 254872 words/s, in_qsize 10, out_qsize 0\n",
      "2025-05-13 11:27:00,554 : INFO : EPOCH 1 - PROGRESS: at 39.35% examples, 253844 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:27:01,613 : INFO : EPOCH 1 - PROGRESS: at 41.01% examples, 253169 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:27:02,666 : INFO : EPOCH 1 - PROGRESS: at 42.71% examples, 253001 words/s, in_qsize 10, out_qsize 0\n",
      "2025-05-13 11:27:03,672 : INFO : EPOCH 1 - PROGRESS: at 44.36% examples, 252919 words/s, in_qsize 10, out_qsize 0\n",
      "2025-05-13 11:27:04,738 : INFO : EPOCH 1 - PROGRESS: at 46.09% examples, 252670 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:27:05,742 : INFO : EPOCH 1 - PROGRESS: at 47.68% examples, 252240 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:27:06,792 : INFO : EPOCH 1 - PROGRESS: at 49.33% examples, 251812 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:27:07,839 : INFO : EPOCH 1 - PROGRESS: at 50.98% examples, 251428 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:27:08,908 : INFO : EPOCH 1 - PROGRESS: at 52.70% examples, 251238 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:27:09,922 : INFO : EPOCH 1 - PROGRESS: at 54.43% examples, 251476 words/s, in_qsize 10, out_qsize 0\n",
      "2025-05-13 11:27:10,976 : INFO : EPOCH 1 - PROGRESS: at 56.15% examples, 251404 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:27:12,045 : INFO : EPOCH 1 - PROGRESS: at 57.87% examples, 251223 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:27:13,114 : INFO : EPOCH 1 - PROGRESS: at 59.59% examples, 251052 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:27:14,230 : INFO : EPOCH 1 - PROGRESS: at 61.32% examples, 250580 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:27:15,362 : INFO : EPOCH 1 - PROGRESS: at 63.06% examples, 250030 words/s, in_qsize 10, out_qsize 0\n",
      "2025-05-13 11:27:16,465 : INFO : EPOCH 1 - PROGRESS: at 64.78% examples, 249698 words/s, in_qsize 10, out_qsize 0\n",
      "2025-05-13 11:27:17,488 : INFO : EPOCH 1 - PROGRESS: at 66.50% examples, 249871 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:27:18,522 : INFO : EPOCH 1 - PROGRESS: at 68.42% examples, 250718 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:27:19,650 : INFO : EPOCH 1 - PROGRESS: at 70.28% examples, 250734 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:27:20,657 : INFO : EPOCH 1 - PROGRESS: at 72.07% examples, 251206 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:27:21,667 : INFO : EPOCH 1 - PROGRESS: at 73.80% examples, 251402 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:27:22,693 : INFO : EPOCH 1 - PROGRESS: at 75.59% examples, 251732 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:27:23,704 : INFO : EPOCH 1 - PROGRESS: at 77.32% examples, 251905 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:27:24,718 : INFO : EPOCH 1 - PROGRESS: at 78.89% examples, 251610 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:27:25,846 : INFO : EPOCH 1 - PROGRESS: at 80.61% examples, 251173 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:27:26,941 : INFO : EPOCH 1 - PROGRESS: at 82.33% examples, 250930 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:27:28,024 : INFO : EPOCH 1 - PROGRESS: at 84.06% examples, 250748 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:27:29,140 : INFO : EPOCH 1 - PROGRESS: at 85.79% examples, 250416 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:27:30,248 : INFO : EPOCH 1 - PROGRESS: at 87.52% examples, 250138 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:27:31,356 : INFO : EPOCH 1 - PROGRESS: at 89.24% examples, 249865 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:27:32,404 : INFO : EPOCH 1 - PROGRESS: at 90.97% examples, 249878 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:27:33,432 : INFO : EPOCH 1 - PROGRESS: at 92.70% examples, 249982 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:27:34,458 : INFO : EPOCH 1 - PROGRESS: at 94.50% examples, 250272 words/s, in_qsize 10, out_qsize 0\n",
      "2025-05-13 11:27:35,518 : INFO : EPOCH 1 - PROGRESS: at 96.14% examples, 250041 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:27:36,598 : INFO : EPOCH 1 - PROGRESS: at 97.87% examples, 249918 words/s, in_qsize 10, out_qsize 0\n",
      "2025-05-13 11:27:37,648 : INFO : EPOCH 1 - PROGRESS: at 99.60% examples, 249916 words/s, in_qsize 6, out_qsize 0\n",
      "2025-05-13 11:27:37,750 : INFO : EPOCH 1: training on 14497168 raw words (15233034 effective words) took 60.8s, 250491 effective words/s\n",
      "2025-05-13 11:27:38,763 : INFO : EPOCH 2 - PROGRESS: at 1.45% examples, 218955 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:27:39,828 : INFO : EPOCH 2 - PROGRESS: at 3.18% examples, 233151 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:27:40,867 : INFO : EPOCH 2 - PROGRESS: at 4.90% examples, 239640 words/s, in_qsize 10, out_qsize 0\n",
      "2025-05-13 11:27:41,870 : INFO : EPOCH 2 - PROGRESS: at 6.68% examples, 247515 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:27:42,896 : INFO : EPOCH 2 - PROGRESS: at 8.35% examples, 247178 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:27:44,015 : INFO : EPOCH 2 - PROGRESS: at 10.07% examples, 244889 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:27:45,060 : INFO : EPOCH 2 - PROGRESS: at 11.79% examples, 245787 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:27:46,157 : INFO : EPOCH 2 - PROGRESS: at 13.53% examples, 244952 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:27:47,164 : INFO : EPOCH 2 - PROGRESS: at 15.19% examples, 245499 words/s, in_qsize 10, out_qsize 0\n",
      "2025-05-13 11:27:48,226 : INFO : EPOCH 2 - PROGRESS: at 16.64% examples, 241677 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:27:49,338 : INFO : EPOCH 2 - PROGRESS: at 18.36% examples, 241110 words/s, in_qsize 10, out_qsize 0\n",
      "2025-05-13 11:27:50,436 : INFO : EPOCH 2 - PROGRESS: at 20.08% examples, 240947 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:27:51,478 : INFO : EPOCH 2 - PROGRESS: at 21.80% examples, 241760 words/s, in_qsize 10, out_qsize 0\n",
      "2025-05-13 11:27:52,539 : INFO : EPOCH 2 - PROGRESS: at 23.53% examples, 242167 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:27:53,603 : INFO : EPOCH 2 - PROGRESS: at 25.24% examples, 242475 words/s, in_qsize 10, out_qsize 0\n",
      "2025-05-13 11:27:54,709 : INFO : EPOCH 2 - PROGRESS: at 26.96% examples, 242126 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:27:55,724 : INFO : EPOCH 2 - PROGRESS: at 28.62% examples, 242485 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:27:56,725 : INFO : EPOCH 2 - PROGRESS: at 30.07% examples, 241304 words/s, in_qsize 10, out_qsize 0\n",
      "2025-05-13 11:27:57,779 : INFO : EPOCH 2 - PROGRESS: at 31.72% examples, 241192 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:27:58,799 : INFO : EPOCH 2 - PROGRESS: at 33.16% examples, 239983 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:27:59,852 : INFO : EPOCH 2 - PROGRESS: at 34.80% examples, 239958 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:28:00,888 : INFO : EPOCH 2 - PROGRESS: at 36.24% examples, 238734 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:28:01,966 : INFO : EPOCH 2 - PROGRESS: at 37.90% examples, 238523 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:28:02,966 : INFO : EPOCH 2 - PROGRESS: at 39.48% examples, 238633 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:28:04,014 : INFO : EPOCH 2 - PROGRESS: at 41.01% examples, 237915 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:28:05,086 : INFO : EPOCH 2 - PROGRESS: at 42.71% examples, 238188 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:28:06,165 : INFO : EPOCH 2 - PROGRESS: at 44.43% examples, 238382 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:28:07,175 : INFO : EPOCH 2 - PROGRESS: at 46.09% examples, 238773 words/s, in_qsize 10, out_qsize 0\n",
      "2025-05-13 11:28:08,254 : INFO : EPOCH 2 - PROGRESS: at 47.61% examples, 237896 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:28:09,331 : INFO : EPOCH 2 - PROGRESS: at 49.33% examples, 238094 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:28:10,351 : INFO : EPOCH 2 - PROGRESS: at 51.04% examples, 238693 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:28:11,372 : INFO : EPOCH 2 - PROGRESS: at 52.77% examples, 239259 words/s, in_qsize 10, out_qsize 0\n",
      "2025-05-13 11:28:12,379 : INFO : EPOCH 2 - PROGRESS: at 54.43% examples, 239585 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:28:13,387 : INFO : EPOCH 2 - PROGRESS: at 56.08% examples, 239884 words/s, in_qsize 10, out_qsize 0\n",
      "2025-05-13 11:28:14,407 : INFO : EPOCH 2 - PROGRESS: at 57.52% examples, 239220 words/s, in_qsize 10, out_qsize 0\n",
      "2025-05-13 11:28:15,458 : INFO : EPOCH 2 - PROGRESS: at 59.25% examples, 239505 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:28:16,469 : INFO : EPOCH 2 - PROGRESS: at 60.84% examples, 239492 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:28:17,477 : INFO : EPOCH 2 - PROGRESS: at 62.43% examples, 239492 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:28:18,495 : INFO : EPOCH 2 - PROGRESS: at 64.10% examples, 239696 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:28:19,546 : INFO : EPOCH 2 - PROGRESS: at 65.81% examples, 239946 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:28:20,603 : INFO : EPOCH 2 - PROGRESS: at 67.53% examples, 240153 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:28:21,675 : INFO : EPOCH 2 - PROGRESS: at 69.25% examples, 240269 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:28:22,777 : INFO : EPOCH 2 - PROGRESS: at 70.97% examples, 240215 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:28:23,835 : INFO : EPOCH 2 - PROGRESS: at 72.69% examples, 240392 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:28:24,894 : INFO : EPOCH 2 - PROGRESS: at 74.41% examples, 240566 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:28:25,898 : INFO : EPOCH 2 - PROGRESS: at 76.07% examples, 240787 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:28:26,925 : INFO : EPOCH 2 - PROGRESS: at 77.59% examples, 240457 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:28:27,966 : INFO : EPOCH 2 - PROGRESS: at 79.23% examples, 240487 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:28:29,019 : INFO : EPOCH 2 - PROGRESS: at 80.88% examples, 240467 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:28:30,039 : INFO : EPOCH 2 - PROGRESS: at 82.33% examples, 239993 words/s, in_qsize 10, out_qsize 0\n",
      "2025-05-13 11:28:31,090 : INFO : EPOCH 2 - PROGRESS: at 83.99% examples, 239992 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:28:32,100 : INFO : EPOCH 2 - PROGRESS: at 85.51% examples, 239782 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:28:33,156 : INFO : EPOCH 2 - PROGRESS: at 87.17% examples, 239761 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:28:34,172 : INFO : EPOCH 2 - PROGRESS: at 88.76% examples, 239720 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:28:35,209 : INFO : EPOCH 2 - PROGRESS: at 90.28% examples, 239416 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:28:36,211 : INFO : EPOCH 2 - PROGRESS: at 91.86% examples, 239447 words/s, in_qsize 10, out_qsize 0\n",
      "2025-05-13 11:28:37,275 : INFO : EPOCH 2 - PROGRESS: at 93.39% examples, 239044 words/s, in_qsize 10, out_qsize 0\n",
      "2025-05-13 11:28:38,278 : INFO : EPOCH 2 - PROGRESS: at 94.98% examples, 239076 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:28:39,302 : INFO : EPOCH 2 - PROGRESS: at 96.50% examples, 238852 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:28:40,313 : INFO : EPOCH 2 - PROGRESS: at 98.15% examples, 239021 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:28:41,339 : INFO : EPOCH 2 - PROGRESS: at 99.67% examples, 238795 words/s, in_qsize 5, out_qsize 0\n",
      "2025-05-13 11:28:41,397 : INFO : EPOCH 2: training on 14497168 raw words (15232906 effective words) took 63.6s, 239359 effective words/s\n",
      "2025-05-13 11:28:42,478 : INFO : EPOCH 3 - PROGRESS: at 1.45% examples, 205215 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:28:43,485 : INFO : EPOCH 3 - PROGRESS: at 3.11% examples, 226976 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:28:44,561 : INFO : EPOCH 3 - PROGRESS: at 4.56% examples, 219491 words/s, in_qsize 9, out_qsize 0\n",
      "2025-05-13 11:28:45,575 : INFO : EPOCH 3 - PROGRESS: at 6.13% examples, 223984 words/s, in_qsize 10, out_qsize 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 34\u001b[0m\n\u001b[0;32m     32\u001b[0m model \u001b[38;5;241m=\u001b[39m Doc2Vec(vector_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, min_count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m, workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m     33\u001b[0m model\u001b[38;5;241m.\u001b[39mbuild_vocab(tagged_data)\n\u001b[1;32m---> 34\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtagged_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorpus_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Get vectors for claim_text\u001b[39;00m\n\u001b[0;32m     38\u001b[0m train_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclaim_vector\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m train_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclaim_text\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m x: model\u001b[38;5;241m.\u001b[39minfer_vector(word_tokenize(\u001b[38;5;28mstr\u001b[39m(x)\u001b[38;5;241m.\u001b[39mlower()))\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m     40\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\gensim\\models\\doc2vec.py:516\u001b[0m, in \u001b[0;36mDoc2Vec.train\u001b[1;34m(self, corpus_iterable, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    513\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moffsets\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m offsets\n\u001b[0;32m    514\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_doctags\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m start_doctags\n\u001b[1;32m--> 516\u001b[0m \u001b[38;5;28msuper\u001b[39m(Doc2Vec, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mtrain(\n\u001b[0;32m    517\u001b[0m     corpus_iterable\u001b[38;5;241m=\u001b[39mcorpus_iterable, corpus_file\u001b[38;5;241m=\u001b[39mcorpus_file,\n\u001b[0;32m    518\u001b[0m     total_examples\u001b[38;5;241m=\u001b[39mtotal_examples, total_words\u001b[38;5;241m=\u001b[39mtotal_words,\n\u001b[0;32m    519\u001b[0m     epochs\u001b[38;5;241m=\u001b[39mepochs, start_alpha\u001b[38;5;241m=\u001b[39mstart_alpha, end_alpha\u001b[38;5;241m=\u001b[39mend_alpha, word_count\u001b[38;5;241m=\u001b[39mword_count,\n\u001b[0;32m    520\u001b[0m     queue_factor\u001b[38;5;241m=\u001b[39mqueue_factor, report_delay\u001b[38;5;241m=\u001b[39mreport_delay, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\gensim\\models\\word2vec.py:1073\u001b[0m, in \u001b[0;36mWord2Vec.train\u001b[1;34m(self, corpus_iterable, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m   1070\u001b[0m     callback\u001b[38;5;241m.\u001b[39mon_epoch_begin(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1072\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m corpus_iterable \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1073\u001b[0m     trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_epoch(\n\u001b[0;32m   1074\u001b[0m         corpus_iterable, cur_epoch\u001b[38;5;241m=\u001b[39mcur_epoch, total_examples\u001b[38;5;241m=\u001b[39mtotal_examples,\n\u001b[0;32m   1075\u001b[0m         total_words\u001b[38;5;241m=\u001b[39mtotal_words, queue_factor\u001b[38;5;241m=\u001b[39mqueue_factor, report_delay\u001b[38;5;241m=\u001b[39mreport_delay,\n\u001b[0;32m   1076\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1077\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1078\u001b[0m     trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_epoch_corpusfile(\n\u001b[0;32m   1079\u001b[0m         corpus_file, cur_epoch\u001b[38;5;241m=\u001b[39mcur_epoch, total_examples\u001b[38;5;241m=\u001b[39mtotal_examples, total_words\u001b[38;5;241m=\u001b[39mtotal_words,\n\u001b[0;32m   1080\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\gensim\\models\\word2vec.py:1434\u001b[0m, in \u001b[0;36mWord2Vec._train_epoch\u001b[1;34m(self, data_iterable, cur_epoch, total_examples, total_words, queue_factor, report_delay, callbacks)\u001b[0m\n\u001b[0;32m   1431\u001b[0m     thread\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# make interrupting the process with ctrl+c easier\u001b[39;00m\n\u001b[0;32m   1432\u001b[0m     thread\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m-> 1434\u001b[0m trained_word_count, raw_word_count, job_tally \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_epoch_progress\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1435\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprogress_queue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_queue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcur_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcur_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_examples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1436\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtotal_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_words\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreport_delay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreport_delay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_corpus_file_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1437\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1439\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trained_word_count, raw_word_count, job_tally\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\gensim\\models\\word2vec.py:1289\u001b[0m, in \u001b[0;36mWord2Vec._log_epoch_progress\u001b[1;34m(self, progress_queue, job_queue, cur_epoch, total_examples, total_words, report_delay, is_corpus_file_mode)\u001b[0m\n\u001b[0;32m   1286\u001b[0m unfinished_worker_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworkers\n\u001b[0;32m   1288\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m unfinished_worker_count \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 1289\u001b[0m     report \u001b[38;5;241m=\u001b[39m \u001b[43mprogress_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# blocks if workers too slow\u001b[39;00m\n\u001b[0;32m   1290\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m report \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# a thread reporting that it finished\u001b[39;00m\n\u001b[0;32m   1291\u001b[0m         unfinished_worker_count \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\queue.py:171\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_qsize():\n\u001b[1;32m--> 171\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be a non-negative number\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Do doc2vec on the evidence_df\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import pandas as pd\n",
    "\n",
    "train_doc = train_df[\"claim_text\"]\n",
    "dev_doc = dev_df[\"claim_text\"]\n",
    "dev_baseline_doc = dev_baseline_df[\"claim_text\"]\n",
    "test_doc = test_df[\"claim_text\"]\n",
    "evidence_doc = evidence_df[\"value\"]\n",
    "tagged_data_raw = (\n",
    "    # train_df[\"claim_text\"].tolist() +\n",
    "    # dev_df[\"claim_text\"].tolist() +\n",
    "    # dev_baseline_df[\"claim_text\"].tolist() +\n",
    "    evidence_df[\"value\"].tolist()\n",
    ")\n",
    "\n",
    "print(tagged_data_raw[0:5])\n",
    "\n",
    "tagged_data = [\n",
    "    TaggedDocument(words=doc, tags=[str(i)])\n",
    "    for i, doc in enumerate(tagged_data_raw)\n",
    "    if isinstance(doc, list) and all(isinstance(w, str) for w in doc)\n",
    "]\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "model = Doc2Vec(vector_size=50, min_count=2, epochs=15, workers=8)\n",
    "model.build_vocab(tagged_data)\n",
    "model.train(tagged_data, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "\n",
    "\n",
    "# Get vectors for claim_text\n",
    "train_df[\"claim_vector\"] = train_df[\"claim_text\"].apply(\n",
    "    lambda x: model.infer_vector(word_tokenize(str(x).lower())).tolist()\n",
    ")\n",
    "\n",
    "print(\"Finished vectorizing train_df claim_text\")\n",
    "\n",
    "dev_df[\"claim_vector\"] = dev_df[\"claim_text\"].apply(\n",
    "    lambda x: model.infer_vector(word_tokenize(str(x).lower())).tolist()\n",
    ")\n",
    "\n",
    "print(\"Finished vectorizing dev_df claim_text\")\n",
    "\n",
    "dev_baseline_df[\"claim_vector\"] = dev_baseline_df[\"claim_text\"].apply(\n",
    "    lambda x: model.infer_vector(word_tokenize(str(x).lower())).tolist()\n",
    ")\n",
    "\n",
    "print(\"Finished vectorizing dev_baseline_df claim_text\")\n",
    "\n",
    "# Get vectors for evidence values\n",
    "evidence_df[\"evidence_vector\"] = evidence_df[\"value\"].apply(\n",
    "    lambda x: model.infer_vector(word_tokenize(str(x).lower())).tolist()\n",
    ")\n",
    "\n",
    "print(\"Finished vectorizing evidence_df value\")\n",
    "\n",
    "print(train_df.head())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30f642e",
   "metadata": {},
   "source": [
    "### Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80305830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   claim_text  \\\n",
      "claim-1937  [scientific, evidence, co2, pollutant, higher,...   \n",
      "claim-126   [el, nio, drove, record, high, global, tempera...   \n",
      "claim-2510                 [1946, pdo, switched, cool, phase]   \n",
      "claim-2021  [weather, channel, cofounder, john, coleman, p...   \n",
      "claim-2449  [january, 2008, capped, 12, month, period, glo...   \n",
      "\n",
      "                                             top_100_evidence  \n",
      "claim-1937  [evidence-143269, evidence-796217, evidence-35...  \n",
      "claim-126   [evidence-743888, evidence-372910, evidence-85...  \n",
      "claim-2510  [evidence-130713, evidence-779638, evidence-10...  \n",
      "claim-2021  [evidence-104597, evidence-563911, evidence-37...  \n",
      "claim-2449  [evidence-1205158, evidence-1203993, evidence-...  \n"
     ]
    }
   ],
   "source": [
    "### Ranking 1: cosine similarity on claim_text with evidence to produce top 100 evidence for each claim\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "similarity_matrix = cosine_similarity(train_df[\"claim_vector\"].tolist(), evidence_df[\"evidence_vector\"].tolist())\n",
    "\n",
    "top_k = 1000\n",
    "top_indices = np.argsort(-similarity_matrix, axis=1)[:, :top_k]  # sort descending, get top 100 indices\n",
    "\n",
    "# Create new column with top evidence texts for each claim\n",
    "train_df[\"top_100_evidence\"] = [\n",
    "    evidence_df.iloc[indices][\"key\"].tolist() for indices in top_indices\n",
    "]\n",
    "\n",
    "print(train_df[[\"claim_text\", \"top_100_evidence\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c93b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['evidence-143269', 'evidence-796217', 'evidence-351732', 'evidence-284457', 'evidence-973135', 'evidence-892094', 'evidence-363147', 'evidence-6413', 'evidence-1010652', 'evidence-145808', 'evidence-53852', 'evidence-754066', 'evidence-172162', 'evidence-429076', 'evidence-707114', 'evidence-259493', 'evidence-765966', 'evidence-25131', 'evidence-1037802', 'evidence-248899', 'evidence-835637', 'evidence-1202020', 'evidence-412151', 'evidence-181754', 'evidence-190926', 'evidence-915997', 'evidence-85124', 'evidence-766720', 'evidence-254468', 'evidence-366694', 'evidence-789604', 'evidence-308217', 'evidence-878386', 'evidence-1077265', 'evidence-41044', 'evidence-407364', 'evidence-18216', 'evidence-366640', 'evidence-334132', 'evidence-288500', 'evidence-544149', 'evidence-1104136', 'evidence-585397', 'evidence-748483', 'evidence-565213', 'evidence-679107', 'evidence-685800', 'evidence-1071199', 'evidence-971926', 'evidence-366455', 'evidence-667021', 'evidence-980491', 'evidence-174734', 'evidence-431625', 'evidence-367423', 'evidence-54062', 'evidence-1019081', 'evidence-375666', 'evidence-551661', 'evidence-132289', 'evidence-1073468', 'evidence-91723', 'evidence-657484', 'evidence-226302', 'evidence-1040583', 'evidence-755268', 'evidence-1144594', 'evidence-925028', 'evidence-949', 'evidence-1111921', 'evidence-641823', 'evidence-115876', 'evidence-935157', 'evidence-693516', 'evidence-1147899', 'evidence-376855', 'evidence-787210', 'evidence-78637', 'evidence-47958', 'evidence-991900', 'evidence-696585', 'evidence-1086157', 'evidence-714078', 'evidence-489160', 'evidence-437872', 'evidence-606962', 'evidence-809288', 'evidence-294661', 'evidence-1084365', 'evidence-888583', 'evidence-640125', 'evidence-1137876', 'evidence-305533', 'evidence-527804', 'evidence-899205', 'evidence-231652', 'evidence-1166104', 'evidence-610564', 'evidence-339010', 'evidence-750645']\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n"
     ]
    }
   ],
   "source": [
    "for i in range(min(100, len(train_df))):\n",
    "    evidence_list = train_df.at[i, \"evidence\"]\n",
    "    top_100_list = train_df.at[i, \"top_100_evidence\"]\n",
    "\n",
    "    if isinstance(evidence_list, list) and isinstance(top_100_list, list):\n",
    "        if any(ev in top_100_list for ev in evidence_list):\n",
    "            print(\"Found it\")\n",
    "            print(\"Claim:\", train_df.at[i, \"claim_text\"])\n",
    "            print(\"Vector:\", train_df.at[i, \"claim_vector\"])\n",
    "            print(\"Top 100 Evidence:\", top_100_list)\n",
    "        else:\n",
    "            print(\"Not found\")\n",
    "    else:\n",
    "        print(f\"Row {i} has invalid data types.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
