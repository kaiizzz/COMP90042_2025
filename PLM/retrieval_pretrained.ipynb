{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "32yCsRUo8H33"
   },
   "source": [
    "# 2025 COMP90042 Project\n",
    "*Make sure you change the file name with your group id.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XCybYoGz8YWQ"
   },
   "source": [
    "# Readme\n",
    "*If there is something to be noted for the marker, please mention here.*\n",
    "\n",
    "*If you are planning to implement a program with Object Oriented Programming style, please put those the bottom of this ipynb file*\n",
    "\n",
    "\n",
    "**This file inlcudes the method to fine-tune the pre-trained Lanaguage Model**\n",
    "\n",
    "**This method uses dual-encoder and cross-encoder**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6po98qVA8bJD"
   },
   "source": [
    "# 1.DataSet Processing\n",
    "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KI21KJ9jpVbR",
    "outputId": "7ddf7cad-5e45-485f-d412-18a3617a425c"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lLqt3rs39KKf",
    "outputId": "0ef7eff0-755e-4083-8a14-f8b44e7de158"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1228 train claims.\n",
      "Loaded 154 dev claims.\n",
      "Loaded 153 test claims.\n",
      "Loaded 1208827 evidence documents.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Set paths\n",
    "data_dir = \"data\"\n",
    "train_claims_file = os.path.join(data_dir, \"train-claims.json\")\n",
    "dev_claims_file = os.path.join(data_dir, \"dev-claims.json\")\n",
    "test_claims_file = os.path.join(data_dir, \"test-claims-unlabelled.json\")\n",
    "evidence_file = os.path.join(data_dir, \"evidence.json\")\n",
    "\n",
    "\n",
    "# Load train claims\n",
    "with open(train_claims_file, 'r') as f:\n",
    "    train_claims = json.load(f)\n",
    "train_ids = list(train_claims.keys())\n",
    "train_texts = [train_claims[claim_id]['claim_text'] for claim_id in train_ids]\n",
    "claim_id_to_train_inidce = {claim_id: i for i, claim_id in enumerate(train_ids)}\n",
    "\n",
    "print(f\"Loaded {len(train_claims)} train claims.\")\n",
    "\n",
    "# Load dev claims\n",
    "with open(dev_claims_file, 'r') as f:\n",
    "    dev_claims = json.load(f)\n",
    "dev_ids = list(dev_claims.keys())\n",
    "dev_texts = [dev_claims[claim_id]['claim_text'] for claim_id in dev_ids]\n",
    "\n",
    "print(f\"Loaded {len(dev_claims)} dev claims.\")\n",
    "\n",
    "# Load test claims\n",
    "with open(test_claims_file, 'r') as f:\n",
    "    test_claims = json.load(f)\n",
    "test_texts = [test_claims[claim_id]['claim_text'] for claim_id in test_claims.keys()]\n",
    "\n",
    "print(f\"Loaded {len(test_claims)} test claims.\")\n",
    "\n",
    "# Load evidence texts\n",
    "with open(evidence_file, 'r') as f:\n",
    "    evidence = json.load(f)\n",
    "\n",
    "evidence_ids = list(evidence.keys())\n",
    "evidence_texts = [evidence[claim_id] for claim_id in evidence_ids]\n",
    "evidence_id_to_train_index = {claim_id: i for i, claim_id in enumerate(evidence_ids)}\n",
    "print(f\"Loaded {len(evidence)} evidence documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 277,
     "referenced_widgets": [
      "5623db5c2072491c8a27987d9eaf978e",
      "5f4a06373136494785da9d9b90e62b1d",
      "efe18b166a514e05829f0a0f08283c4c",
      "b2556b5269ac4f0e9022a95b65910c59",
      "6f46fed65c7b4df6a0a50ee5dfff2d89",
      "ffd295d61db24fb789148b8066f92b0b",
      "bc8c7f0d03124f778380acd8428cb8e1",
      "6b69080064b6432994bc70e605345f39",
      "4c2fc4b09863477ebfce192c893ce967",
      "95a36e62283545988f3279adb3fe9248",
      "8a9c7be708c44c1e9ae3d4890b5d7e66",
      "1854dafb3ab74728b4e81541f00b3666",
      "1e218b77184c42aead76bb994f464e22",
      "edd6fce7255140a282e98ae8e056bab2",
      "df6c240ffdf6472d9c3976061c303093",
      "86767469270c4890b153d0f0b7faabcd",
      "77090f7b214b450e9d6eb17ea9e76114",
      "10c4d002a1d74375976b115251f4cf6c",
      "7b3757fc30d54c778cc1feca1586591d",
      "7d6c6c8133a14f9fa30d2ead6ea9fe54",
      "8915e026a5114e9181abc2a58490e4a6",
      "ab134788ded242429da7f38d64103c03",
      "a42e3b79cc8245b6bc50961438fcfade",
      "8b3793b93cd843d8984d11aa6f8ba0a2",
      "11c334ce93444ee2be50376729650635",
      "16c8e4895a6c4deaa3eb2de9f25aaa83",
      "74e3cf072d0a4ce29d061ecb0b74b727",
      "f32f6e9ccd374d77859d5f436cde15f3",
      "474461141f4540258cb520326731a6a0",
      "5e18aae5a7714ebb9011a5d14fc6a3d1",
      "6b18653d9e3a434a846610db6ceed241",
      "47d781a79dfe4d8dab5caf50173b43dc",
      "fd5b571dd90e41bd8c5139150f2164bd",
      "e099003274464cb6872f2cac561ff14e",
      "463b1e49523246b08acec7a2a87bbeb1",
      "7d9159bba61e453a811be12f12944a94",
      "fd2c672290f14f4c94b5c2d3485baecd",
      "560db4f277d342938b270349e6b5676c",
      "b9e5d56320714a999d2bf110bfce10c3",
      "6b6ef0646b9c4396b247ce241725db86",
      "35acb55c38fc404592b71378f3e5d072",
      "de8bd815ca8f4161accda8be24ed3c74",
      "871105ae44af4f398181e9b7ca08beb3",
      "9964285b2804436495c3a5a69e94e4da"
     ]
    },
    "id": "2cDfiR-Y9KKg",
    "outputId": "f52d4cb5-3c9e-4dea-b34c-d117d1742b31"
   },
   "outputs": [],
   "source": [
    "model_name = \"sentence-transformers/multi-qa-MiniLM-L6-cos-v1\"\n",
    "# model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "import torch\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, max_len=512)\n",
    "# model = AutoModel.from_pretrained(model_name).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1FA2ao2l8hOg"
   },
   "source": [
    "# 2. Model Implementation\n",
    "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "QIEqDDT78q39"
   },
   "outputs": [],
   "source": [
    "def contrastive_loss(claim_embedding, pos_evidence_embeddings, neg_evidence_embeddings,  temperature=0.02):\n",
    "    \"\"\"Compute improved contrastive loss with lower temperature for better discrimination\"\"\"\n",
    "    # Compute positive and negative similarities\n",
    "    pos_sim = torch.exp(torch.matmul(claim_embedding, pos_evidence_embeddings.T) / temperature).sum()\n",
    "    neg_sim = torch.exp(torch.matmul(claim_embedding, neg_evidence_embeddings.T) / temperature).sum()\n",
    "\n",
    "    # Compute contrastive loss\n",
    "    loss = -torch.log(pos_sim / (pos_sim + neg_sim))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "8IypswAW9KKh"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def generate_all_embeddings(model, texts, batch_size=32):\n",
    "    \"\"\"Generate embeddings for all texts\"\"\"\n",
    "    model.eval()\n",
    "    all_embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, len(texts), batch_size)):\n",
    "            batch_texts = texts[i:i + batch_size]\n",
    "            inputs = tokenizer(batch_texts, padding=True, truncation=True, return_tensors='pt').to(model.device)\n",
    "            outputs = model(**inputs)\n",
    "            embeddings = outputs.last_hidden_state[:, 0, :].cpu()  # CLS token\n",
    "            all_embeddings.append(embeddings)\n",
    "            torch.cuda.empty_cache()\n",
    "    return torch.cat(all_embeddings)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "def get_test_f_scores(test_texts, test_claims, test_ids, evidence_texts, evidence_indice_to_claim_id, model, batch_size=32):\n",
    "    \"\"\"Get F-scores for test claims\"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # Generate test claim embeddings\n",
    "    test_claim_embeddings = generate_all_embeddings(model, test_texts, batch_size=batch_size)\n",
    "\n",
    "    # Generate evidence embeddings\n",
    "    evidence_embeddings = generate_all_embeddings(model, evidence_texts, batch_size=batch_size*10)\n",
    "\n",
    "    # Compute cosine similarities\n",
    "    norm_test_claim_embeddings = F.normalize(test_claim_embeddings, p=2, dim=1)\n",
    "    norm_evidence_embeddings = F.normalize(evidence_embeddings, p=2, dim=1)\n",
    "    similarities = torch.matmul(norm_test_claim_embeddings, norm_evidence_embeddings.T)\n",
    "\n",
    "    # Get top-k evidence indices for each claim\n",
    "    top_k = 5\n",
    "    top_k_indices = torch.topk(similarities, top_k, dim=1).indices\n",
    "    top_k_indices = top_k_indices.numpy()\n",
    "\n",
    "    # Compute F-scores\n",
    "    f_scores = []\n",
    "    for i, claim_id in enumerate(test_ids):\n",
    "        # Get the evidence indices for the claim\n",
    "        true_evidence_indices = test_claims[claim_id][\"evidences\"]\n",
    "\n",
    "        # Get the predicted evidence indices\n",
    "        predicted_evidence_indices = top_k_indices[i]\n",
    "        predicted_evidence_indices = [evidence_indice_to_claim_id[evidence_index] for evidence_index in predicted_evidence_indices]\n",
    "\n",
    "        # Compute precision and recall\n",
    "        true_positives = len(set(true_evidence_indices) & set(predicted_evidence_indices))\n",
    "        precision = true_positives / len(predicted_evidence_indices) if len(predicted_evidence_indices) > 0 else 0.0\n",
    "        recall = true_positives / len(true_evidence_indices) if len(true_evidence_indices) > 0 else 0.0\n",
    "\n",
    "        # Compute F-score\n",
    "        f_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "        f_scores.append(f_score)\n",
    "    model.train()\n",
    "    return np.mean(f_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training part —— Alternating between TF-IDF and model-based hard negatives every two epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qXTQe28IRVtl",
    "outputId": "32774658-c55c-4efc-ea4b-103d5d839584"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 11:31:02.626031: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-15 11:31:02.645752: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747279862.671287    3814 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747279862.678983    3814 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1747279862.698431    3814 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747279862.698451    3814 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747279862.698453    3814 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747279862.698455    3814 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-15 11:31:02.705108: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "Epoch 1: Using TF-IDF hard negatives\n",
      "Step 1\n",
      "Step 2\n",
      "Step 3\n",
      "Step 4\n",
      "Step 5\n",
      "Step 6\n",
      "Step 7\n",
      "Step 8\n",
      "Step 9\n",
      "Step 10\n",
      "Step 11\n",
      "Step 12\n",
      "Step 13\n",
      "Step 14\n",
      "Step 15\n",
      "Step 16\n",
      "Step 17\n",
      "Step 18\n",
      "Step 19\n",
      "Step 20\n",
      "Loss: 1.1409674882888794\n",
      "Epoch 2/15\n",
      "Step 21\n",
      "Step 22\n",
      "Step 23\n",
      "Step 24\n",
      "Step 25\n",
      "Step 26\n",
      "Step 27\n",
      "Step 28\n",
      "Step 29\n",
      "Step 30\n",
      "Step 31\n",
      "Step 32\n",
      "Step 33\n",
      "Step 34\n",
      "Step 35\n",
      "Step 36\n",
      "Step 37\n",
      "Step 38\n",
      "Step 39\n",
      "Step 40\n",
      "Loss: 0.037253983318805695\n",
      "Epoch 3/15\n",
      "Epoch 3: Updating hard negatives using current model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering hard negatives: 100%|██████████| 1228/1228 [00:35<00:00, 34.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 41\n",
      "Step 42\n",
      "Step 43\n",
      "Step 44\n",
      "Step 45\n",
      "Step 46\n",
      "Step 47\n",
      "Step 48\n",
      "Step 49\n",
      "Step 50\n",
      "Step 51\n",
      "Step 52\n",
      "Step 53\n",
      "Step 54\n",
      "Step 55\n",
      "Step 56\n",
      "Step 57\n",
      "Step 58\n",
      "Step 59\n",
      "Step 60\n",
      "Loss: 0.6349079012870789\n",
      "Epoch 4/15\n",
      "Step 61\n",
      "Step 62\n",
      "Step 63\n",
      "Step 64\n",
      "Step 65\n",
      "Step 66\n",
      "Step 67\n",
      "Step 68\n",
      "Step 69\n",
      "Step 70\n",
      "Step 71\n",
      "Step 72\n",
      "Step 73\n",
      "Step 74\n",
      "Step 75\n",
      "Step 76\n",
      "Step 77\n",
      "Step 78\n",
      "Step 79\n",
      "Step 80\n",
      "Loss: 0.18634456396102905\n",
      "Epoch 5/15\n",
      "Epoch 5: Using TF-IDF hard negatives\n",
      "Step 81\n",
      "Step 82\n",
      "Step 83\n",
      "Step 84\n",
      "Step 85\n",
      "Step 86\n",
      "Step 87\n",
      "Step 88\n",
      "Step 89\n",
      "Step 90\n",
      "Step 91\n",
      "Step 92\n",
      "Step 93\n",
      "Step 94\n",
      "Step 95\n",
      "Step 96\n",
      "Step 97\n",
      "Step 98\n",
      "Step 99\n",
      "Step 100\n",
      "Loss: 0.15157179534435272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 83.90it/s]\n",
      "100%|██████████| 1889/1889 [07:02<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-score on dev set: 0.16284271284271284\n",
      "New best F-score: 0.16284271284271284\n",
      "Epoch 6/15\n",
      "Step 101\n",
      "Step 102\n",
      "Step 103\n",
      "Step 104\n",
      "Step 105\n",
      "Step 106\n",
      "Step 107\n",
      "Step 108\n",
      "Step 109\n",
      "Step 110\n",
      "Step 111\n",
      "Step 112\n",
      "Step 113\n",
      "Step 114\n",
      "Step 115\n",
      "Step 116\n",
      "Step 117\n",
      "Step 118\n",
      "Step 119\n",
      "Step 120\n",
      "Loss: 0.24049368500709534\n",
      "Epoch 7/15\n",
      "Epoch 7: Updating hard negatives using current model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering hard negatives: 100%|██████████| 1228/1228 [00:35<00:00, 34.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 121\n",
      "Step 122\n",
      "Step 123\n",
      "Step 124\n",
      "Step 125\n",
      "Step 126\n",
      "Step 127\n",
      "Step 128\n",
      "Step 129\n",
      "Step 130\n",
      "Step 131\n",
      "Step 132\n",
      "Step 133\n",
      "Step 134\n",
      "Step 135\n",
      "Step 136\n",
      "Step 137\n",
      "Step 138\n",
      "Step 139\n",
      "Step 140\n",
      "Loss: 0.06903477758169174\n",
      "Epoch 8/15\n",
      "Step 141\n",
      "Step 142\n",
      "Step 143\n",
      "Step 144\n",
      "Step 145\n",
      "Step 146\n",
      "Step 147\n",
      "Step 148\n",
      "Step 149\n",
      "Step 150\n",
      "Step 151\n",
      "Step 152\n",
      "Step 153\n",
      "Step 154\n",
      "Step 155\n",
      "Step 156\n",
      "Step 157\n",
      "Step 158\n",
      "Step 159\n",
      "Step 160\n",
      "Loss: 0.2752847969532013\n",
      "Epoch 9/15\n",
      "Epoch 9: Using TF-IDF hard negatives\n",
      "Step 161\n",
      "Step 162\n",
      "Step 163\n",
      "Step 164\n",
      "Step 165\n",
      "Step 166\n",
      "Step 167\n",
      "Step 168\n",
      "Step 169\n",
      "Step 170\n",
      "Step 171\n",
      "Step 172\n",
      "Step 173\n",
      "Step 174\n",
      "Step 175\n",
      "Step 176\n",
      "Step 177\n",
      "Step 178\n",
      "Step 179\n",
      "Step 180\n",
      "Loss: 0.09241817891597748\n",
      "Epoch 10/15\n",
      "Step 181\n",
      "Step 182\n",
      "Step 183\n",
      "Step 184\n",
      "Step 185\n",
      "Step 186\n",
      "Step 187\n",
      "Step 188\n",
      "Step 189\n",
      "Step 190\n",
      "Step 191\n",
      "Step 192\n",
      "Step 193\n",
      "Step 194\n",
      "Step 195\n",
      "Step 196\n",
      "Step 197\n",
      "Step 198\n",
      "Step 199\n",
      "Step 200\n",
      "Loss: 0.18410101532936096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 73.27it/s]\n",
      "100%|██████████| 1889/1889 [07:09<00:00,  4.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-score on dev set: 0.15777674706246136\n",
      "Epoch 11/15\n",
      "Epoch 11: Updating hard negatives using current model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering hard negatives: 100%|██████████| 1228/1228 [00:35<00:00, 34.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 201\n",
      "Step 202\n",
      "Step 203\n",
      "Step 204\n",
      "Step 205\n",
      "Step 206\n",
      "Step 207\n",
      "Step 208\n",
      "Step 209\n",
      "Step 210\n",
      "Step 211\n",
      "Step 212\n",
      "Step 213\n",
      "Step 214\n",
      "Step 215\n",
      "Step 216\n",
      "Step 217\n",
      "Step 218\n",
      "Step 219\n",
      "Step 220\n",
      "Loss: 0.04094647616147995\n",
      "Epoch 12/15\n",
      "Step 221\n",
      "Step 222\n",
      "Step 223\n",
      "Step 224\n",
      "Step 225\n",
      "Step 226\n",
      "Step 227\n",
      "Step 228\n",
      "Step 229\n",
      "Step 230\n",
      "Step 231\n",
      "Step 232\n",
      "Step 233\n",
      "Step 234\n",
      "Step 235\n",
      "Step 236\n",
      "Step 237\n",
      "Step 238\n",
      "Step 239\n",
      "Step 240\n",
      "Loss: 0.05835933983325958\n",
      "Epoch 13/15\n",
      "Epoch 13: Using TF-IDF hard negatives\n",
      "Step 241\n",
      "Step 242\n",
      "Step 243\n",
      "Step 244\n",
      "Step 245\n",
      "Step 246\n",
      "Step 247\n",
      "Step 248\n",
      "Step 249\n",
      "Step 250\n",
      "Step 251\n",
      "Step 252\n",
      "Step 253\n",
      "Step 254\n",
      "Step 255\n",
      "Step 256\n",
      "Step 257\n",
      "Step 258\n",
      "Step 259\n",
      "Step 260\n",
      "Loss: 0.15600687265396118\n",
      "Epoch 14/15\n",
      "Step 261\n",
      "Step 262\n",
      "Step 263\n",
      "Step 264\n",
      "Step 265\n",
      "Step 266\n",
      "Step 267\n",
      "Step 268\n",
      "Step 269\n",
      "Step 270\n",
      "Step 271\n",
      "Step 272\n",
      "Step 273\n",
      "Step 274\n",
      "Step 275\n",
      "Step 276\n",
      "Step 277\n",
      "Step 278\n",
      "Step 279\n",
      "Step 280\n",
      "Loss: 0.22706279158592224\n",
      "Epoch 15/15\n",
      "Epoch 15: Updating hard negatives using current model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering hard negatives: 100%|██████████| 1228/1228 [00:35<00:00, 34.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 281\n",
      "Step 282\n",
      "Step 283\n",
      "Step 284\n",
      "Step 285\n",
      "Step 286\n",
      "Step 287\n",
      "Step 288\n",
      "Step 289\n",
      "Step 290\n",
      "Step 291\n",
      "Step 292\n",
      "Step 293\n",
      "Step 294\n",
      "Step 295\n",
      "Step 296\n",
      "Step 297\n",
      "Step 298\n",
      "Step 299\n",
      "Step 300\n",
      "Loss: 0.029318323358893394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 84.28it/s]\n",
      "100%|██████████| 1889/1889 [07:04<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-score on dev set: 0.15389610389610392\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "# Training configuration\n",
    "max_epochs = 15\n",
    "batch_size = 64\n",
    "learning_rate = 5e-5\n",
    "test_interval = 100  # Test every 100 steps\n",
    "log_interval = 20    # Log every 20 steps\n",
    "update_frequency = 2 # Update hard negatives every 2 epochs\n",
    "best_f1 = 0\n",
    "\n",
    "# Initialize model\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "model.cuda()\n",
    "\n",
    "# Define optimizer with learning rate scheduler\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=max_epochs)\n",
    "\n",
    "# Set random seed for reproducibility \n",
    "random.seed(330)\n",
    "torch.manual_seed(330)\n",
    "torch.cuda.manual_seed_all(330)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Load pre-computed TF-IDF hard negatives\n",
    "with open(os.path.join(data_dir, \"hard_negatives.json\"), 'r') as f:\n",
    "    tfidf_hard_negatives = json.load(f)\n",
    "\n",
    "# Initialize hard negatives dictionary with TF-IDF results\n",
    "hard_negatives_dict = tfidf_hard_negatives.copy()\n",
    "\n",
    "step = 0\n",
    "max_score = 0.0\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{max_epochs}\")\n",
    "    random.shuffle(train_ids)\n",
    "\n",
    "    # Alternate between TF-IDF and model-based hard negatives\n",
    "    use_tfidf = (epoch % (update_frequency * 2) == 0)  # True for epochs 0, 4, 8...\n",
    "    use_model = (epoch % update_frequency == 0 and not use_tfidf)  # True for epochs 2, 6...\n",
    "\n",
    "    if use_tfidf:\n",
    "        print(f\"Epoch {epoch + 1}: Using TF-IDF hard negatives\")\n",
    "        hard_negatives_dict = tfidf_hard_negatives.copy()\n",
    "\n",
    "    elif use_model:\n",
    "        print(f\"Epoch {epoch + 1}: Updating hard negatives using current model\")\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            # Filter TF-IDF hard negatives using current model\n",
    "            for claim_id in tqdm(train_claims.keys(), desc=\"Filtering hard negatives\"):\n",
    "                # Get claim embedding\n",
    "                claim_text = train_claims[claim_id]['claim_text']\n",
    "                inputs = tokenizer(claim_text, padding=True, truncation=True, return_tensors='pt').to(model.device)\n",
    "                claim_embedding = model(**inputs).last_hidden_state[:, 0, :]\n",
    "                norm_claim_embedding = F.normalize(claim_embedding, p=2, dim=1)\n",
    "\n",
    "                # Fix KeyError - check if claim_id exists in tfidf_hard_negatives\n",
    "                if claim_id not in tfidf_hard_negatives:\n",
    "                    hard_negatives_dict[claim_id] = []\n",
    "                    continue\n",
    "                    \n",
    "                # Get TF-IDF candidates\n",
    "                tfidf_candidates = tfidf_hard_negatives[claim_id]\n",
    "                candidate_evidence_ids = [neg['evidence_id'] for neg in tfidf_candidates]\n",
    "                candidate_texts = [evidence[eid] for eid in candidate_evidence_ids]\n",
    "\n",
    "                if not candidate_texts:  # Skip if no candidates\n",
    "                    continue\n",
    "\n",
    "                # Calculate similarities with current model\n",
    "                inputs = tokenizer(\n",
    "                    candidate_texts,\n",
    "                    padding=True,\n",
    "                    truncation=True,\n",
    "                    max_length=256,\n",
    "                    return_tensors='pt'\n",
    "                ).to(model.device)\n",
    "\n",
    "                evidence_embeddings = model(**inputs).last_hidden_state[:, 0, :]\n",
    "                norm_evidence_embeddings = F.normalize(evidence_embeddings, p=2, dim=1)\n",
    "\n",
    "                similarities = torch.matmul(norm_claim_embedding, norm_evidence_embeddings.T)\n",
    "                similarities = similarities[0].cpu().numpy()\n",
    "\n",
    "                # Get moderate difficulty negatives (rank 10-20)\n",
    "                if len(similarities) > 20:\n",
    "                    top_indices = np.argsort(similarities)[-20:-10]  # Get samples ranked 10-20\n",
    "                else:\n",
    "                    top_indices = np.argsort(similarities)[-5:]  # Fallback to top 5 if not enough candidates\n",
    "\n",
    "                # Update hard negatives for this claim\n",
    "                new_hard_negatives = []\n",
    "                for idx in top_indices:\n",
    "                    evidence_id = candidate_evidence_ids[idx]\n",
    "                    if evidence_id not in train_claims[claim_id]['evidences']:\n",
    "                        new_hard_negatives.append({\n",
    "                            'evidence_id': evidence_id,\n",
    "                            'similarity': float(similarities[idx])\n",
    "                        })\n",
    "\n",
    "                hard_negatives_dict[claim_id] = new_hard_negatives\n",
    "\n",
    "        model.train()\n",
    "\n",
    "    # Training loop\n",
    "    for i in range(0, len(train_ids), batch_size):\n",
    "        step += 1\n",
    "        print(f\"Step {step}\")\n",
    "        batch_ids = train_ids[i:i + batch_size]\n",
    "        batch_claims = [train_claims[claim_id] for claim_id in batch_ids]\n",
    "        batch_indices = [claim_id_to_train_inidce[claim_id] for claim_id in batch_ids]\n",
    "\n",
    "        # Get evidence indices including current hard negatives\n",
    "        evidence_indices = []\n",
    "        pos_evidence_positive_indices = []\n",
    "        for claim_id, claim in zip(batch_ids, batch_claims):\n",
    "            # Add positive samples\n",
    "            positive_indices = []\n",
    "            for evidence_id in claim[\"evidences\"][:2]:  # Use at most 2 positive samples\n",
    "                evidence_idx = evidence_id_to_train_index[evidence_id]\n",
    "                if evidence_idx not in evidence_indices:\n",
    "                    evidence_indices.append(evidence_idx)\n",
    "                positive_indices.append(len(evidence_indices) - 1)\n",
    "\n",
    "            # Fix KeyError - check if claim_id exists in hard_negatives_dict\n",
    "            if claim_id in hard_negatives_dict:\n",
    "                hard_negs = hard_negatives_dict[claim_id][:3]  # Use top 3 hard negatives\n",
    "                for neg in hard_negs:\n",
    "                    neg_idx = evidence_id_to_train_index[neg['evidence_id']]\n",
    "                    if neg_idx not in evidence_indices:\n",
    "                        evidence_indices.append(neg_idx)\n",
    "            \n",
    "            pos_evidence_positive_indices.append(positive_indices)\n",
    "\n",
    "        # Get claim embeddings\n",
    "        claim_texts = [train_texts[i] for i in batch_indices]\n",
    "        model_inputs = tokenizer(claim_texts, padding=True, truncation=True, return_tensors='pt').to(model.device)\n",
    "        claim_embeddings = model(**model_inputs).last_hidden_state[:, 0, :]\n",
    "        norm_claim_embeddings = F.normalize(claim_embeddings, p=2, dim=1)\n",
    "\n",
    "        # Get evidence embeddings\n",
    "        cur_evidence_indices = [evidence_texts[evidence_indice] for evidence_indice in evidence_indices]\n",
    "        evidence_model_inputs = tokenizer(\n",
    "            cur_evidence_indices,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=256,\n",
    "            return_tensors='pt'\n",
    "        ).to(model.device)\n",
    "\n",
    "        evidence_embeddings = model(**evidence_model_inputs).last_hidden_state[:, 0, :]\n",
    "        norm_evidence_embeddings = F.normalize(evidence_embeddings, p=2, dim=1)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = []\n",
    "        for i, claim_embedding in enumerate(norm_claim_embeddings):\n",
    "            pos_evidence_embeddings = norm_evidence_embeddings[torch.tensor(pos_evidence_positive_indices[i])]\n",
    "            neg_evidence_embeddings = norm_evidence_embeddings[torch.tensor([j for j in range(len(evidence_indices))\n",
    "                                                               if j not in pos_evidence_positive_indices[i]])]\n",
    "            loss.append(contrastive_loss(claim_embedding, pos_evidence_embeddings, neg_evidence_embeddings))\n",
    "        loss = torch.mean(torch.stack(loss))\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Clear cache\n",
    "        del evidence_embeddings, norm_evidence_embeddings\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        if step % log_interval == 0:\n",
    "            print(f\"Loss: {loss.item()}\")\n",
    "\n",
    "        if step % test_interval == 0:\n",
    "            # Evaluate on dev set\n",
    "            f_score = get_test_f_scores(dev_texts, dev_claims, dev_ids, evidence_texts, evidence_ids, model, batch_size=batch_size)\n",
    "            print(f\"F-score on dev set: {f_score}\")\n",
    "            # Save model\n",
    "            torch.save(model.state_dict(), f\"model_epoch_{epoch + 1}_step_{step}.pth\")\n",
    "            if f_score > max_score:\n",
    "                max_score = f_score\n",
    "                print(f\"New best F-score: {max_score}\")\n",
    "                torch.save(model.state_dict(), \"best_model.pth\")\n",
    "    \n",
    "    # Update learning rate\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EzGuzHPE87Ya"
   },
   "source": [
    "# 3.Testing and Evaluation\n",
    "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-encoder for reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on dev set...\n",
      "Baseline without reranking:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 66.61it/s]\n",
      "100%|██████████| 1889/1889 [07:05<00:00,  4.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline F-score on dev set: 0.1628\n",
      "\n",
      "With reranking:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 67.29it/s]\n",
      "100%|██████████| 3778/3778 [06:27<00:00,  9.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked F-score on dev set: 0.2064\n",
      "Improvement: 4.35%\n"
     ]
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained(model_name)  # First initialize the original model architecture\n",
    "model.load_state_dict(torch.load(\"best_model.pth\"), strict=False)  # Then load the trained weights\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "# Initialize cross-encoder\n",
    "cross_encoder_name = \"cross-encoder/ms-marco-MiniLM-L-6-v2\"\n",
    "cross_encoder = AutoModelForSequenceClassification.from_pretrained(cross_encoder_name).cuda()\n",
    "cross_encoder_tokenizer = AutoTokenizer.from_pretrained(cross_encoder_name)\n",
    "\n",
    "optimizer = torch.optim.AdamW(cross_encoder.parameters(), lr=1e-5)\n",
    "\n",
    "# Reranking function\n",
    "def rerank_evidences(claim, candidate_evidence_ids, candidate_texts, model, tokenizer, top_k=10):\n",
    "    \"\"\"Rerank candidate evidences using a cross-encoder model\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Create input pairs: (claim, evidence)\n",
    "    paired_texts = []\n",
    "    for evidence_text in candidate_texts:\n",
    "        paired_texts.append([claim, evidence_text])\n",
    "    \n",
    "    # Score each pair\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer(\n",
    "            paired_texts,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "            max_length=256\n",
    "        ).to(model.device)\n",
    "        \n",
    "        scores = model(**inputs).logits.squeeze(-1).cpu().numpy()\n",
    "    \n",
    "    # Rerank based on scores\n",
    "    reranked_indices = np.argsort(-scores)\n",
    "    reranked_evidence_ids = [candidate_evidence_ids[i] for i in reranked_indices[:top_k]]\n",
    "    \n",
    "    return reranked_evidence_ids\n",
    "\n",
    "# Evaluation function to calculate F-scores\n",
    "def evaluate_with_reranking(test_texts, test_claims, test_ids, evidence_texts, evidence_ids,\n",
    "                           initial_model, cross_encoder, cross_encoder_tokenizer,\n",
    "                           batch_size=16, initial_k=50, final_k=5):\n",
    "    \"\"\"Evaluate F-score of the two-stage retrieval system\"\"\"\n",
    "    initial_model.eval()\n",
    "    cross_encoder.eval()\n",
    "    \n",
    "    # Generate test claim embeddings\n",
    "    test_claims_embeddings = generate_all_embeddings(initial_model, test_texts, batch_size=batch_size)\n",
    "    \n",
    "    # Generate evidence embeddings\n",
    "    test_evidence_embeddings = generate_all_embeddings(initial_model, evidence_texts, batch_size=batch_size*10)\n",
    "    \n",
    "    # Normalize embeddings\n",
    "    norm_test_claim_embeddings = F.normalize(test_claims_embeddings, p=2, dim=1)\n",
    "    norm_evidence_embeddings = F.normalize(test_evidence_embeddings, p=2, dim=1)\n",
    "    \n",
    "    # First stage: compute similarities and get initial candidates\n",
    "    similarities = torch.matmul(norm_test_claim_embeddings, norm_evidence_embeddings.T)\n",
    "    top_k_initial = torch.topk(similarities, initial_k, dim=1).indices.numpy()\n",
    "    \n",
    "    # Calculate F-scores\n",
    "    f_scores = []\n",
    "    for i, claim_id in enumerate(test_ids):\n",
    "        # Get true evidence\n",
    "        true_evidence_ids = test_claims[claim_id][\"evidences\"]\n",
    "        \n",
    "        # Get claim text\n",
    "        claim_text = test_claims[claim_id][\"claim_text\"]\n",
    "        \n",
    "        # Get first-stage candidates\n",
    "        candidate_indices = top_k_initial[i]\n",
    "        candidate_evidence_ids = [evidence_ids[idx] for idx in candidate_indices]\n",
    "        candidate_texts = [evidence_texts[idx] for idx in candidate_indices]\n",
    "        \n",
    "        # Rerank using cross-encoder\n",
    "        reranked_evidence_ids = rerank_evidences(\n",
    "            claim_text, \n",
    "            candidate_evidence_ids, \n",
    "            candidate_texts, \n",
    "            cross_encoder, \n",
    "            cross_encoder_tokenizer, \n",
    "            top_k=final_k\n",
    "        )\n",
    "        \n",
    "        # Calculate precision and recall\n",
    "        true_positives = len(set(true_evidence_ids) & set(reranked_evidence_ids))\n",
    "        precision = true_positives / len(reranked_evidence_ids) if len(reranked_evidence_ids) > 0 else 0.0\n",
    "        recall = true_positives / len(true_evidence_ids) if len(true_evidence_ids) > 0 else 0.0\n",
    "        \n",
    "        # Calculate F-score\n",
    "        f_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "        f_scores.append(f_score)\n",
    "        \n",
    "        # Print results for each sample\n",
    "        # print(f\"Claim {i+1}/{len(test_ids)}: F-score = {f_score:.4f}, P = {precision:.4f}, R = {recall:.4f}\")\n",
    "        \n",
    "    return np.mean(f_scores)\n",
    "\n",
    "#  Evaluate on dev set\n",
    "print(\"Evaluating on dev set...\")\n",
    "# First evaluate baseline without reranking\n",
    "print(\"Baseline without reranking:\")\n",
    "baseline_f1 = get_test_f_scores(dev_texts, dev_claims, dev_ids, evidence_texts, evidence_ids, model, batch_size=64)\n",
    "print(f\"Baseline F-score on dev set: {baseline_f1:.4f}\")\n",
    "\n",
    "# Then evaluate with reranking\n",
    "print(\"\\nWith reranking:\")\n",
    "reranked_f1 = evaluate_with_reranking(\n",
    "    dev_texts, dev_claims, dev_ids, evidence_texts, evidence_ids,\n",
    "    model, cross_encoder, cross_encoder_tokenizer,\n",
    "    batch_size=32, initial_k=50, final_k=5)\n",
    "\n",
    "print(f\"Reranked F-score on dev set: {reranked_f1:.4f}\")\n",
    "print(f\"Improvement: {(reranked_f1 - baseline_f1) * 100:.2f}%\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate test predictions with reranking\n",
    "def generate_test_predictions_with_reranking(test_texts, test_claims, test_ids, evidence_texts, evidence_ids,\n",
    "                                           initial_model, cross_encoder, cross_encoder_tokenizer,\n",
    "                                           batch_size=16, initial_k=50, final_k=5):\n",
    "    \"\"\"Generate test predictions with two-stage retrieval (retrieval + reranking)\"\"\"\n",
    "    initial_model.eval()\n",
    "    cross_encoder.eval()\n",
    "    \n",
    "    # Generate test claim embeddings\n",
    "    test_claims_embeddings = generate_all_embeddings(initial_model, test_texts, batch_size=batch_size)\n",
    "    \n",
    "    # Generate evidence embeddings\n",
    "    test_evidence_embeddings = generate_all_embeddings(initial_model, evidence_texts, batch_size=batch_size*10)\n",
    "    \n",
    "    # Normalize embeddings\n",
    "    norm_test_claim_embeddings = F.normalize(test_claims_embeddings, p=2, dim=1)\n",
    "    norm_evidence_embeddings = F.normalize(test_evidence_embeddings, p=2, dim=1)\n",
    "    \n",
    "    # First stage: compute similarities and get initial candidates\n",
    "    similarities = torch.matmul(norm_test_claim_embeddings, norm_evidence_embeddings.T)\n",
    "    top_k_initial = torch.topk(similarities, initial_k, dim=1).indices.numpy()\n",
    "    \n",
    "    # Second stage: rerank and save results\n",
    "    results = test_claims.copy()\n",
    "    for i, claim_id in enumerate(test_ids):\n",
    "        # Get claim text\n",
    "        claim_text = test_claims[claim_id]['claim_text']\n",
    "        \n",
    "        # Get first-stage candidates\n",
    "        candidate_indices = top_k_initial[i]\n",
    "        candidate_evidence_ids = [evidence_ids[idx] for idx in candidate_indices]\n",
    "        candidate_texts = [evidence_texts[idx] for idx in candidate_indices]\n",
    "        \n",
    "        # Rerank with cross-encoder\n",
    "        reranked_evidence_ids = rerank_evidences(\n",
    "            claim_text, \n",
    "            candidate_evidence_ids, \n",
    "            candidate_texts, \n",
    "            cross_encoder, \n",
    "            cross_encoder_tokenizer, \n",
    "            top_k=final_k\n",
    "        )\n",
    "        \n",
    "        # Store final results\n",
    "        results[claim_id]['evidences'] = reranked_evidence_ids\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating test set predictions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 88.90it/s]\n",
      "100%|██████████| 3778/3778 [06:34<00:00,  9.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to data/test_claims_retrieved_reranked.json\n"
     ]
    }
   ],
   "source": [
    "# Generate test set predictions\n",
    "print(\"\\nGenerating test set predictions...\")\n",
    "test_claims_ids = list(test_claims.keys())\n",
    "results = generate_test_predictions_with_reranking(\n",
    "    test_texts, test_claims, test_claims_ids, evidence_texts, evidence_ids,\n",
    "    model, cross_encoder, cross_encoder_tokenizer,\n",
    "    batch_size=32, initial_k=50, final_k=5\n",
    ")\n",
    "\n",
    "output_file = os.path.join(data_dir, \"test_claims_retrieved_reranked.json\")\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(results, f, indent=4)\n",
    "print(f\"Results saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mefSOe8eTmGP",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Object Oriented Programming codes here\n",
    "\n",
    "*You can use multiple code snippets. Just add more if needed*"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "10c4d002a1d74375976b115251f4cf6c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "11c334ce93444ee2be50376729650635": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5e18aae5a7714ebb9011a5d14fc6a3d1",
      "max": 466247,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6b18653d9e3a434a846610db6ceed241",
      "value": 466247
     }
    },
    "16c8e4895a6c4deaa3eb2de9f25aaa83": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_47d781a79dfe4d8dab5caf50173b43dc",
      "placeholder": "​",
      "style": "IPY_MODEL_fd5b571dd90e41bd8c5139150f2164bd",
      "value": " 466k/466k [00:00&lt;00:00, 28.6MB/s]"
     }
    },
    "1854dafb3ab74728b4e81541f00b3666": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1e218b77184c42aead76bb994f464e22",
       "IPY_MODEL_edd6fce7255140a282e98ae8e056bab2",
       "IPY_MODEL_df6c240ffdf6472d9c3976061c303093"
      ],
      "layout": "IPY_MODEL_86767469270c4890b153d0f0b7faabcd"
     }
    },
    "1e218b77184c42aead76bb994f464e22": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_77090f7b214b450e9d6eb17ea9e76114",
      "placeholder": "​",
      "style": "IPY_MODEL_10c4d002a1d74375976b115251f4cf6c",
      "value": "vocab.txt: 100%"
     }
    },
    "35acb55c38fc404592b71378f3e5d072": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "463b1e49523246b08acec7a2a87bbeb1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b9e5d56320714a999d2bf110bfce10c3",
      "placeholder": "​",
      "style": "IPY_MODEL_6b6ef0646b9c4396b247ce241725db86",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "474461141f4540258cb520326731a6a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "47d781a79dfe4d8dab5caf50173b43dc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4c2fc4b09863477ebfce192c893ce967": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "560db4f277d342938b270349e6b5676c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5623db5c2072491c8a27987d9eaf978e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5f4a06373136494785da9d9b90e62b1d",
       "IPY_MODEL_efe18b166a514e05829f0a0f08283c4c",
       "IPY_MODEL_b2556b5269ac4f0e9022a95b65910c59"
      ],
      "layout": "IPY_MODEL_6f46fed65c7b4df6a0a50ee5dfff2d89"
     }
    },
    "5e18aae5a7714ebb9011a5d14fc6a3d1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5f4a06373136494785da9d9b90e62b1d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ffd295d61db24fb789148b8066f92b0b",
      "placeholder": "​",
      "style": "IPY_MODEL_bc8c7f0d03124f778380acd8428cb8e1",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "6b18653d9e3a434a846610db6ceed241": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6b69080064b6432994bc70e605345f39": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6b6ef0646b9c4396b247ce241725db86": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6f46fed65c7b4df6a0a50ee5dfff2d89": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "74e3cf072d0a4ce29d061ecb0b74b727": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "77090f7b214b450e9d6eb17ea9e76114": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7b3757fc30d54c778cc1feca1586591d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7d6c6c8133a14f9fa30d2ead6ea9fe54": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7d9159bba61e453a811be12f12944a94": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_35acb55c38fc404592b71378f3e5d072",
      "max": 112,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_de8bd815ca8f4161accda8be24ed3c74",
      "value": 112
     }
    },
    "86767469270c4890b153d0f0b7faabcd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "871105ae44af4f398181e9b7ca08beb3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8915e026a5114e9181abc2a58490e4a6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8a9c7be708c44c1e9ae3d4890b5d7e66": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8b3793b93cd843d8984d11aa6f8ba0a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f32f6e9ccd374d77859d5f436cde15f3",
      "placeholder": "​",
      "style": "IPY_MODEL_474461141f4540258cb520326731a6a0",
      "value": "tokenizer.json: 100%"
     }
    },
    "95a36e62283545988f3279adb3fe9248": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9964285b2804436495c3a5a69e94e4da": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a42e3b79cc8245b6bc50961438fcfade": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8b3793b93cd843d8984d11aa6f8ba0a2",
       "IPY_MODEL_11c334ce93444ee2be50376729650635",
       "IPY_MODEL_16c8e4895a6c4deaa3eb2de9f25aaa83"
      ],
      "layout": "IPY_MODEL_74e3cf072d0a4ce29d061ecb0b74b727"
     }
    },
    "ab134788ded242429da7f38d64103c03": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b2556b5269ac4f0e9022a95b65910c59": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_95a36e62283545988f3279adb3fe9248",
      "placeholder": "​",
      "style": "IPY_MODEL_8a9c7be708c44c1e9ae3d4890b5d7e66",
      "value": " 383/383 [00:00&lt;00:00, 46.9kB/s]"
     }
    },
    "b9e5d56320714a999d2bf110bfce10c3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bc8c7f0d03124f778380acd8428cb8e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "de8bd815ca8f4161accda8be24ed3c74": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "df6c240ffdf6472d9c3976061c303093": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8915e026a5114e9181abc2a58490e4a6",
      "placeholder": "​",
      "style": "IPY_MODEL_ab134788ded242429da7f38d64103c03",
      "value": " 232k/232k [00:00&lt;00:00, 14.2MB/s]"
     }
    },
    "e099003274464cb6872f2cac561ff14e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_463b1e49523246b08acec7a2a87bbeb1",
       "IPY_MODEL_7d9159bba61e453a811be12f12944a94",
       "IPY_MODEL_fd2c672290f14f4c94b5c2d3485baecd"
      ],
      "layout": "IPY_MODEL_560db4f277d342938b270349e6b5676c"
     }
    },
    "edd6fce7255140a282e98ae8e056bab2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7b3757fc30d54c778cc1feca1586591d",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7d6c6c8133a14f9fa30d2ead6ea9fe54",
      "value": 231508
     }
    },
    "efe18b166a514e05829f0a0f08283c4c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6b69080064b6432994bc70e605345f39",
      "max": 383,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4c2fc4b09863477ebfce192c893ce967",
      "value": 383
     }
    },
    "f32f6e9ccd374d77859d5f436cde15f3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fd2c672290f14f4c94b5c2d3485baecd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_871105ae44af4f398181e9b7ca08beb3",
      "placeholder": "​",
      "style": "IPY_MODEL_9964285b2804436495c3a5a69e94e4da",
      "value": " 112/112 [00:00&lt;00:00, 14.6kB/s]"
     }
    },
    "fd5b571dd90e41bd8c5139150f2164bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ffd295d61db24fb789148b8066f92b0b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
